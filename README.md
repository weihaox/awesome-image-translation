# <p align=center>`awesome image-to-image translation`</p>
[![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)](https://github.com/sindresorhus/awesome)
[![Maintenance](https://img.shields.io/badge/Maintained%3F-yes-blue.svg)](https://GitHub.com/Naereen/StrapDown.js/graphs/commit-activity)
[![PR's Welcome](https://img.shields.io/badge/PRs-welcome-blue.svg?style=flat)](http://makeapullrequest.com) 
![GitHub contributors](https://img.shields.io/github/contributors/weihaox/awesome-image-translation?color=blue)
![visitors](https://visitor-badge.glitch.me/badge?style=flat-square&page_id=weihaox/awesome-image-translation) 

A collection of resources on image-to-image translation. 

## Contributing

Feedback and contributions are welcome! If you think I have missed out on something (or) have any suggestions (papers, implementations and other resources), feel free to [pull a request](https://github.com/xiaweihao/awesome-image-translation/pulls). You could manually edit items or use the [script](https://github.com/weihaox/arxiv_daily_tools) to produce them in the markdown format.

``` markdown
**Here is the Paper Name.**<br>
*[Author 1](homepage), Author 2, and Author 3.*<br>
Conference or Journal Year. [[PDF](link)] [[Project](link)] [[Github](link)] [[Video](link)] [[Data](link)]
```

<details><summary>Table of Contents</summary><p>

- [2023](#2023)
- [2022](#2022)
  * [NeurIPS 2022](#neurips-2022)
  * [ECCV 2022](#eccv-2022)
  * [CVPR 2022](#cvpr-2022)
  * [Others](#others)
- [2021](#2021)
  * [ICCV 2021](#iccv-2021)
  * [CVPR 2021](#cvpr-2021)
  * [ICLR 2021](#iclr-2021)
  * [Others 2021](#others-2021)
- [2020](#2020)
  * [ECCV 2020](#eccv-2020)
  * [CVPR 2020](#cvpr-2020)
  * [AAAI 2020](#aaai-2020)
  * [ACM MM 2020](#acm-mm-2020)
  * [Journal 2020](#journal-2020)
  * [Others 2020](#others-2020)
- [2019](#2019)
  * [NeurIPS 2019](#neurips-2019)
  * [ICCV 2019](#iccv-2019)
  * [CVPR 2019](#cvpr-2019)
  * [ICLR 2019](#iclr-2019)
  * [Journal 2019](#journal-2019)
  * [Others 2019](#others-2019)
- [Before 2018](#before-2018)
</p></details><p></p>


## 2023

### AAAI 2023
**SHUNIT: Style Harmonization for Unpaired Image-to-Image Translation.**[[PDF](https://arxiv.org/abs/2301.04685)]<br>
*Seokbeom Song, Suhyeon Lee, Hongje Seong, Kyoungwon Min, Euntai Kim.*<br>

### WACV 2023

**Panoptic-Aware Image-to-Image Translation.**[[PDF](https://openaccess.thecvf.com/content/WACV2023/html/Zhang_Panoptic-Aware_Image-to-Image_Translation_WACV_2023_paper.html)]<br>
*Liyun Zhang, Photchara Ratsamee, Bowen Wang, Zhaojie Luo, Yuki Uranishi, Manabu Higashida, Haruo Takemura.*<br>

**RIFT: Disentangled Unsupervised Image Translation via Restricted Information Flow.**[[PDF](https://openaccess.thecvf.com/content/WACV2023/html/Usman_RIFT_Disentangled_Unsupervised_Image_Translation_via_Restricted_Information_Flow_WACV_2023_paper.html)]<br>
*Ben Usman, Dina Bashkirova, Kate Saenko.*<br>

**WHFL: Wavelet-Domain High Frequency Loss for Sketch-to-Image Translation.**[[PDF](https://openaccess.thecvf.com/content/WACV2023/html/Kim_WHFL_Wavelet-Domain_High_Frequency_Loss_for_Sketch-to-Image_Translation_WACV_2023_paper.html)]<br>
*Min Woo Kim, Nam Ik Cho.*<br>

### Others 2023

**I2SB: Image-to-Image Schrödinger Bridge.**<br>
*[Guan-Horng Liu](https://ghliu.github.io/), Arash Vahdat, De-An Huang, Evangelos A. Theodorou, Weili Nie, Anima Anandkumar.*<br>
arxiv 2023. [[PDF](https://arxiv.org/abs/2302.05872)] [[Project](https://i2sb.github.io/)]

**Diffusion-based Image Translation using Disentangled Style and Content Representation.**<br>
*[Gihyun Kwon](https://sites.google.com/view/gihyunkwon), [Jong Chul Ye](https://bispl.weebly.com/professor.html).*<br>
ICLR 2023. [[PDF](https://arxiv.org/abs/2209.15264)] [[Github](https://github.com/anon294384/DiffuseIT)]

**Dual Diffusion Implicit Bridges for Image-to-Image Translation.**<br>
*[Xuan Su](https://github.com/suxuann/ddib), [Jiaming Song](https://tsong.me/), [Chenlin Meng](https://cs.stanford.edu/~chenlin/), [Stefano Ermon](https://cs.stanford.edu/~ermon/).*<br>
ICLR 2023. [[PDF](https://arxiv.org/abs/2203.08382)] [[Github](https://github.com/suxuann/ddib)]

## 2022

### NeurIPS 2022
[[accepted paper list](https://neurips.cc/virtual/2022/papers.html)]

**EGSDE: Unpaired Image-to-Image Translation via Energy-Guided Stochastic Differential Equations.**[[PDF](https://arxiv.org/abs/2207.06635)] [[Github](https://github.com/ML-GSAI/EGSDE)]<br>
*Min Zhao, Fan Bao, Chongxuan Li, Jun Zhu.*<br>

**Unsupervised Image-to-Image Translation with Density Changing Regularization.**[[PDF](https://openreview.net/pdf?id=RNZ8JOmNaV4)] [[Github](https://github.com/Mid-Push/Decent)]<br>
*Shaoan Xie, Qirong Ho, Kun Zhang.*<br>

### ECCV 2022
[[accepted paper list](https://www.ecva.net/papers.php)]

**RABIT: Bi-level Feature Alignment for Versatile Image Translation and Manipulation.**[[PDF](https://arxiv.org/abs/2107.03021)] [[Github](https://github.com/fnzhan/RABIT)]<br>
*Fangneng Zhan, Yingchen Yu, Rongliang Wu, Kaiwen Cui, Aoran Xiao, Shijian Lu, Ling Shao.*<br>

**Multi-Curve Translator for High-Resolution Photorealistic Image Translation.**[[PDF](https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136750124.pdf)]<br>
*Yuda Song, Hui Qian, Xin Du.*<br>

**Fast-Vid2Vid: Spatial-Temporal Compression for Video-to-Video Synthesis.**[[PDF](https://arxiv.org/abs/2207.05049)] [[Project](https://fast-vid2vid.github.io/)] [[Github](https://github.com/fast-vid2vid/fast-vid2vid)]<br> 
*Long Zhuo, Guangcong Wang, Shikai Li, Wayne Wu, Ziwei Liu.*<br> 

**ManiFest: Manifold Deformation for Few-shot Image Translation.**[[PDF](https://arxiv.org/abs/2111.13681)] [[GitHub](https://github.com/cv-rits/Manifest)]<br>
*[Fabio Pizzati](https://fabvio.github.io), [Jean-François Lalonde](http://vision.gel.ulaval.ca/~jflalonde/), [Raoul de Charette](https://team.inria.fr/rits/membres/raoul-de-charette/).*<br>

**Vector Quantized Image-to-Image Translation.**[[PDF](https://arxiv.org/abs/2207.13286)] [[Project](https://cyj407.github.io/VQ-I2I/)] [[Github](https://github.com/cyj407/VQ-I2I)]<br>
*[Yu-Jie Chen](cyj407.cs09g@nctu.edu.tw), [Shin-I Cheng](shinicheng.cs09g@nctu.edu.tw), [Wei-Chen Chiu](https://walonchiu.github.io/#publications), [Hung-Yu Tseng](https://hytseng0509.github.io/), [Hsin-Ying Lee](http://hsinyinglee.com/).*<br>

**Unpaired Image Translation via Vector Symbolic Architectures.**[[PDF](https://arxiv.org/abs/2209.02686)] [[Project](https://github.com/facebookresearch/vsait)]<br>
*Justin Theiss, Jay Leverett, Daeil Kim, Aayush Prakash.*

### CVPR 2022

**UNIST: Unpaired Neural Implicit Shape Translation Network.**[[PDF](https://arxiv.org/abs/2110.00966)] [[Project](https://qiminchen.github.io/unist/)] [[Github](https://github.com/qiminchen/UNIST)]<br>
*[Qimin Chen](https://qiminchen.github.io/), [Johannes Merz](), [Aditya Sanghi](https://www.autodesk.com/research/people/aditya-sanghi), [Hooman Shayani](https://www.autodesk.com/research/people/hooman-shayani), [Ali Mahdavi-Amiri](https://www.sfu.ca/~amahdavi/Home.html), [Hao (Richard) Zhang](https://www.cs.sfu.ca/~haoz/).*<br>

**DiffusionCLIP: Text-Guided Diffusion Models for Robust Image Manipulation.**[[PDF](https://arxiv.org/abs/2110.02711)] [[Github](https://github.com/gwang-kim/DiffusionCLIP)]<br>
*Gwanghyun Kim, Taesung Kwon, Jong Chul Ye.*<br>

**Exploring Patch-Wise Semantic Relation for Contrastive Learning in Image-to-Image Translation Tasks.**[[PDF](http://arxiv.org/abs/2203.01532)]<br> 
*Chanyong Jung, Gihyun Kwon, Jong Chul Ye.*<br> 

**InstaFormer: Instance-Aware Image-to-Image Translation with Transformer.**[[PDF](https://arxiv.org/abs/2203.16248)]<br> 
*Soohyun Kim, Jongbeom Baek, Jihye Park, Gyeongnyeon Kim, Seungryong Kim.*<br> 

**A Style-aware Discriminator for Controllable Image Translation.**[[PDF](https://arxiv.org/abs/2203.15375)] [[Github](https://github.com/kunheek/style-aware-discriminator)]<br> 
*[Kunhee Kim](https://www.kunheekim.xyz/), Sanghun Park, Eunyeong Jeon, Taehun Kim, Daijin Kim.*<br> 

**Maximum Spatial Perturbation Consistency for Unpaired Image-to-Image Translation.**[[PDF](https://arxiv.org/abs/2203.12707)][[Github](https://github.com/batmanlab/MSPC)]<br> 
*[Yanwu Xu](http://xuyanwu.github.io/), Shaoan Xie, Wenhao Wu, Kun Zhang, [Mingming Gong](https://mingming-gong.github.io/), [Kayhan Batmanghelich](https://kayhan.dbmi.pitt.edu/).*<br> 

**Modulated Contrast for Versatile Image Synthesis.**[[PDF](https://arxiv.org/abs/2203.09333)][[Github](https://github.com/fnzhan/MoNCE)]<br>
*[Fangneng Zhan](https://fnzhan.com), Jiahui Zhang, Yingchen Yu, Rongliang Wu, Shijian Lu.*<br> 

**Marginal Contrastive Correspondence for Guided Image Generation.**[[PDF](https://arxiv.org/abs/2204.00442)]<br>
*Fangneng Zhan, Yingchen Yu, Rongliang Wu, Jiahui Zhang, Shijian Lu, Changgong Zhang.*<br>

**QS-Attn: Query-Selected Attention for Contrastive Learning in I2I Translation.**[[PDF](https://arxiv.org/abs/2203.08483)][[Github](https://github.com/sapphire497/query-selected-attention)]<br>
*Xueqi Hu, Xinyue Zhou, Qiusheng Huang, Zhengyi Shi, Li Sun, Qingli Li.*<br> 

**Wavelet Knowledge Distillation: Towards Efficient Image-to-Image Translation.**[[PDF](https://arxiv.org/abs/2203.06321)]<br>
*Linfeng Zhang, Xin Chen, Xiaobing Tu, Pengfei Wan, Ning Xu, Kaisheng Ma.*<br> 

**Unsupervised Image-to-Image Translation with Generative Prior.**[[PDF](https://arxiv.org/abs/2204.03641)] [[Project](https://www.mmlab-ntu.com/project/gpunit/)] [[Github](https://github.com/williamyang1991/GP-UNIT)]<br> 
*[Shuai Yang](https://williamyang1991.github.io/), [Liming Jiang](https://liming-jiang.com/), Ziwei Liu, Chen Change Loy.*<br> 

**FlexIT: Towards Flexible Semantic Image Translation.**[[PDF](https://arxiv.org/abs/2203.04705)]<br> 
*Guillaume Couairon, Asya Grechka, Jakob Verbeek, Holger Schwenk, Matthieu Cord.*<br> 

### AAAI 2022

**OA-FSUI2IT: A Novel Few-Shot Cross Domain Object Detection Framework with Object-aware Few-shot Unsupervised Image-to-Image Translation.**<br> 
*Lifan Zhao, Yunlong Meng, Lin Xu.*<br> 

**Style-Guided and Disentangled Representation for Robust Image-to-Image Translation.**<br> 
*Jaewoong Choi, Daeha Kim, Byung Cheol Song.*<br> 

**Learning Temporally and Semantically Consistent Unpaired Video-to-Video Translation through PseudoSupervision from Synthetic Optical Flow.**<br> 
*Kaihong Wang, Kumar Akash, Teruhisa Misu.*<br> 

### Others 2022

**BBDM: Image-to-image Translation with Brownian Bridge Diffusion Models.**<br>
*Bo Li, Kaitao Xue, Bin Liu, Yu-Kun Lai.*<br>                
arxiv 2022. [[PDF](https://arxiv.org/abs/2205.07680)]

**DSI2I: Dense Style for Unpaired Image-to-Image Translation.**<br>
*Baran Ozaydin, Tong Zhang, Sabine Susstrunk, Mathieu Salzmann.*<br>
arxiv 2022. [[PDF](https://arxiv.org/abs/2212.13253)]

**DiffGAR: Model-Agnostic Restoration from Generative Artifacts Using Image-to-Image Diffusion Models.**<br>
*Yueqin Yin, Lianghua Huang, Yu Liu, Kaiqi Huang.*<br>
arxiv 2022. [[PDF](https://arxiv.org/abs/2210.08573)]

**MIDMs: Matching Interleaved Diffusion Models for Exemplar-based Image Translation.**<br>
*[Junyoung Seo](https://github.com/Seokju-Cho), Gyuseong Lee, Seokju Cho, Jiyoung Lee, Seungryong Kim.*<br>
arxiv 2022. [[PDF](https://arxiv.org/abs/2209.11047)] [[Project](https://ku-cvlab.github.io/MIDMs/)]

**StyleFlow For Content-Fixed Image to Image Translation.**<br>
*Weichen Fan, Jinghuan Chen, Jiabin Ma, Jun Hou, Shuai Yi.*<br>
arxiv 2022. [[PDF](https://arxiv.org/abs/2207.01909)] [[Github](https://github.com/weepiess/StyleFlow-Content-Fixed-I2I)]

**PI-Trans: Parallel-ConvMLP and Implicit-Transformation Based GAN for Cross-View Image Translation.**<br>
*Bin Ren, Hao Tang, Yiming Wang, Xia Li, Wei Wang, Nicu Sebe.*<br>
arxiv 2022. [[PDF](https://arxiv.org/abs/2207.04242)] [[Github](https://github.com/Amazingren/PI-Trans)]

**Region-aware Knowledge Distillation for Efficient Image-to-Image Translation.**<br>
*Linfeng Zhang, Xin Chen, Runpei Dong, Kaisheng Ma.*<br>
arxiv 2022. [[PDF](https://arxiv.org/abs/2205.12451)]

**Pretraining is All You Need for Image-to-Image Translation.**<br>
*Tengfei Wang, Ting Zhang, Bo Zhang, Hao Ouyang, Dong Chen, Qifeng Chen, Fang Wen.*<br>
arxiv 2022. [[PDF](https://arxiv.org/abs/2205.12952)] [[Project](https://tengfei-wang.github.io/PITI/index.html)]

**The Swiss Army Knife for Image-to-Image Translation: Multi-Task Diffusion Models.**<br>
*Julia Wolleb, Robin Sandkühler, Florentin Bieder, Philippe C. Cattin.*<br>
arxiv 2022. [[PDF](https://arxiv.org/abs/2204.02641)]

**ITTR: Unpaired Image-to-Image Translation with Transformers.**<br>
*Wanfeng Zheng, Qiang Li, Guoxin Zhang, Pengfei Wan, Zhongyuan Wang.*<br>
arxiv 2022. [[PDF](https://arxiv.org/abs/2203.16015)] [[Github](https://github.com/lucidrains/ITTR-pytorch)]

**Semi-Supervised Image-to-Image Translation using Latent Space Mapping.**<br>
*Pan Zhang, Jianmin Bao, Ting Zhang, Dong Chen, Fang Wen.*<br>
arxiv 2022. [[PDF](https://arxiv.org/abs/2203.15241)]

**Beyond a Video Frame Interpolator: A Space Decoupled Learning Approach to Continuous Image Transition.**<br>
*[Tao Yang](https://cg.cs.tsinghua.edu.cn/people/~tyang), Peiran Ren, Xuansong Xie, Xiansheng Hua, Lei Zhang.*<br>
arxiv 2022. [[PDF](https://arxiv.org/abs/2203.09771)] [[Github](https://github.com/yangxy/SDL)]

**Image-to-Image Translation with Text Guidance.**<br>
*Bowen Li, Xiaojuan Qi, Philip H. S. Torr, Thomas Lukasiewicz.*<br>                
BMVC 2022. [[PDF](https://arxiv.org/abs/2002.05235)]

**Single Image Texture Translation for Data Augmentation.**<br>
*Boyi Li, Yin Cui, Tsung-Yi Lin, Serge Belongie.*<br>
ECCV 2022 Workshop on Learning from Limited and Imperfect Data (L2ID). [[PDF](https://arxiv.org/abs/2106.13804)] [[Github](https://github.com/Boyiliee/SITT)]

**StyleGAN-NADA: CLIP-Guided Domain Adaptation of Image Generators.**<br>
*[Rinon Gal](https://rinongal.github.io/), [Or Patashnik](https://orpatashnik.github.io/), [Haggai Maron](https://haggaim.github.io/), [Gal Chechik](https://research.nvidia.com/person/gal-chechik), [Daniel Cohen-Or](https://www.cs.tau.ac.il/~dcor/).*<br>
SIGGRAPH 2022. [[PDF](https://arxiv.org/abs/2108.00946)] [[Project](https://stylegan-nada.github.io/)] [[Github](https://github.com/rinongal/StyleGAN-nada)]

**Palette: Image-to-Image Diffusion Models.**<br>
*Chitwan Saharia, William Chan, Huiwen Chang, Chris A. Lee, Jonathan Ho, Tim Salimans, David J. Fleet, Mohammad Norouzi.*<br>
SIGGRAPH 2022. [[PDF](https://arxiv.org/abs/2111.05826)]

**Fix the Noise: Disentangling Source Feature for Transfer Learning of StyleGAN.**<br>
*Dongyeun Lee, Jae Young Lee, Doyeon Kim, Jaehyun Choi, Junmo Kim.*<br>
CVPR 2022 Workshop on AI for Content Creation (AICC 2022). [[PDF](https://arxiv.org/abs/2204.14079)]

**Unsupervised Multi-Modal Medical Image Registration via Discriminator-Free Image-to-Image Translation.**<br>
*Zekang Chen, Jia Wei, Rui Li.*<br>
IJCAI 2022. [[PDF](https://arxiv.org/abs/2204.13656)]

**Quality Metric Guided Portrait Line Drawing Generation from Unpaired Training Data.**<br>
*Ran Yi, Yong-Jin Liu, Yu-Kun Lai, Paul Rosin.*<br>
TPAMI 2022. [[PDF](https://ieeexplore.ieee.org/abstract/document/9699090)]

**SAVI2I: Continuous and Diverse Image-to-Image Translation via Signed Attribute Vectors.**<br>
*Qi Mao, Hsin-Ying Lee, Hung-Yu Tseng, Jia-Bin Huang, Siwei Ma, Ming-Hsuan Yang.*<br>
IJCV 2022. [[PDF](https://arxiv.org/abs/2011.01215)] [[Project](https://helenmao.github.io/SAVI2I/)] [[Github](https://github.com/HelenMao/SAVI2I)]

**Distilling GANs with Style-Mixed Triplets for X2I Translation with Limited Data.**<br>
*Yaxing Wang, Joost van de weijer, Lu Yu, Shangling Jui.*<br>
ICLR 2022. [[PDF](https://openreview.net/forum?id=QjOQkpzKbNk)]

## 2021

### ICCV 2021
[[accepted paper list](https://openaccess.thecvf.com/ICCV2021)]


**Image Shape Manipulation from A Single Augmented Training Sample.**[PDF](https://arxiv.org/abs/2007.01289)] [[Project](http://www.vision.huji.ac.il/deepsim/)] [[Github](https://github.com/eliahuhorwitz/DeepSIM)]<br>
*[Yael Vinker](https://www.linkedin.com/in/yael-vinker-a91a00157/), [Eliahu Horwitz](https://www.linkedin.com/in/eliahu-horwitz), Nir Zabari, [Yedid Hoshen](http://www.cs.huji.ac.il/~ydidh).*<br>

**Frequency Domain Image Translation: More Photo-realistic, Better Identity-preserving.** [[PDF](https://arxiv.org/abs/2011.13611)]<br>
*Mu Cai, Hong Zhang, Huijuan Huang, Qichuan Geng, Yixuan Li, Gao Huang.*<br>                

**Semantically Robust Unpaired Image Translation for Data with Unmatched Semantics Statistics.**[[PDF](https://arxiv.org/abs/2012.04932)]<br>
*Zhiwei Jia, Bodi Yuan, Kangkang Wang, Hong Wu, David Clifford, Zhiqiang Yuan, Hao Su.*<br>                

**Harnessing the Conditioning Sensorium for Improved Image Translation.**[[PDF](https://arxiv.org/abs/2110.06443)]<br>
*Cooper Nederhood, Nicholas Kolkin, Deqing Fu, Jason Salavon.*<br>

**Bridging the Gap Between Label- and Reference-Based Synthesis in Multi-Attribute Image-to-Image Translation.**[[PDF](https://arxiv.org/pdf/2103.02264)] [[Github](https://github.com/huangqiusheng/BridgeGAN)]<br> 
*Qiusheng Huang, Zhilin Zheng, Xueqi Hu, Li Sun, Qingli Li.*<br> 

**Dual Transfer Learning for Event-Based End-Task Prediction via Pluggable Event to Image Translation.**[[PDF](https://openaccess.thecvf.com/content/ICCV2021/html/Wang_Dual_Transfer_Learning_for_Event-Based_End-Task_Prediction_via_Pluggable_Event_ICCV_2021_paper.html)]<br> 
*Lin Wang, Yujeong Chae, Kuk-Jin Yoon.*<br> 

**TransferI2I: Transfer Learning for Image-to-Image Translation From Small Datasets.**[[PDF](https://openaccess.thecvf.com/content/ICCV2021/html/Wang_TransferI2I_Transfer_Learning_for_Image-to-Image_Translation_From_Small_Datasets_ICCV_2021_paper.html)]<br> 
*Yaxing Wang, Hector Laria, Joost van de Weijer, Laura Lopez-Fuentes, Bogdan Raducanu.*<br> 

**Harnessing the Conditioning Sensorium for Improved Image Translation
.**[[PDF](https://openaccess.thecvf.com/content/ICCV2021/html/Nederhood_Harnessing_the_Conditioning_Sensorium_for_Improved_Image_Translation_ICCV_2021_paper.html)]<br>
*Cooper Nederhood, Nicholas Kolkin, Deqing Fu, Jason Salavon.*<br>

**Frequency Domain Image Translation: More Photo-Realistic, Better Identity-Preserving.**[[PDF](http://arxiv.org/abs/2011.13611)]<br>
*Mu Cai, Hong Zhang, Huijuan Huang, Qichuan Geng, Yixuan Li, Gao Huang.*<br>

**Attack As the Best Defense: Nullifying Image-to-Image Translation GANs via Limit-Aware Adversarial Attack.**[[PDF](https://openaccess.thecvf.com/content/ICCV2021/html/Yeh_Attack_As_the_Best_Defense_Nullifying_Image-to-Image_Translation_GANs_via_ICCV_2021_paper.html)]<br>
*Chin-Yuan Yeh, Hsi-Wen Chen, Hong-Han Shuai, De-Nian Yang, Ming-Syan Chen.*<br>

**Semantically Robust Unpaired Image Translation for Data With Unmatched Semantics Statistics.**[[PDF](https://openaccess.thecvf.com/content/ICCV2021/html/Jia_Semantically_Robust_Unpaired_Image_Translation_for_Data_With_Unmatched_Semantics_ICCV_2021_paper.html)] [[Github](https://github.com/SeanJia/SRUNIT)]<br> 
*Zhiwei Jia, Bodi Yuan, Kangkang Wang, Hong Wu, David Clifford, Zhiqiang Yuan, Hao Su.*<br> 

**IrwGAN: Unaligned Image-to-Image Translation by Learning to Reweight.**[[PDF](https://arxiv.org/abs/2109.11736)][[Github](https://github.com/Mid-Push/IrwGAN)]<br> 
*Shaoan Xie, Mingming Gong, Yanwu Xu, Kun Zhang.*<br> 

**SPatchGAN: A Statistical Feature Based Discriminator for Unsupervised Image-to-Image Translation.**[[PDF](https://arxiv.org/abs/2103.16219)] [[Github](https://github.com/NetEase-GameAI/SPatchGAN)]<br> 
*Xuning Shao, Weidong Zhang.*<br> 

**OverLORD: Scaling-up Disentanglement for Image Translation.**[[PDF](https://arxiv.org/abs/2103.14017)] [[Github](https://github.com/avivga/overlord)]<br> 
*Aviv Gabbay, Yedid Hoshen.*<br> 

**Diagonal Attention and Style-based GAN for Content-Style Disentanglement in Image Generation and Translation.**[[PDF](https://arxiv.org/abs/2103.16146)] [[Supplementary Materials](https://openaccess.thecvf.com/content/ICCV2021/supplemental/Kwon_Diagonal_Attention_and_ICCV_2021_supplemental.pdf)] [[Github](https://github.com/KwonGihyun/DiagonalGAN)] <br>
*Gihyun Kwon, Jong Chul Ye.*<br> 

**GANcraft: Unsupervised 3D Neural Rendering of Minecraft Worlds.**[[PDF](https://arxiv.org/pdf/2104.07659.pdf)][[Project](https://nvlabs.github.io/GANcraft/)] [[Github](https://github.com/NVlabs/imaginaire)]<br>
*[Zekun Hao](https://www.cs.cornell.edu/~zekun/), [Arun Mallya](http://arunmallya.github.io/), [Serge Belongie](https://vision.cornell.edu/se3/people/serge-belongie/), [Ming-Yu Liu](http://mingyuliu.net/).*<br>

**TUNIT: Rethinking the Truly Unsupervised Image-to-Image Translation.**[[PDF](https://arxiv.org/abs/2006.05734)] [[Github](https://github.com/clovaai/tunit)]<br>
*Kyungjune Baek, Yunjey Choi, Youngjung Uh, Jaejun Yoo, Hyunjung Shim.*<br>

**Long-Term Temporally Consistent Unpaired Video Translation from Simulated Surgical 3D Data.**[[PDF](https://arxiv.org/abs/2103.17204)]<br>
*Dominik Rivoir, Micha Pfeiffer, Reuben Docea, Fiona Kolbinger, Carina Riediger, Jürgen Weitz, Stefanie Speidel.*<br>

**Instance-wise Hard Negative Example Generation for Contrastive Learning in Unpaired Image-to-Image Translation.**[[PDF](https://arxiv.org/abs/2108.04547)]<br>
*Weilun Wang, Wengang Zhou, Jianmin Bao, Dong Chen, Houqiang Li.*<br>

### CVPR 2021
[[accepted paper list](https://openaccess.thecvf.com/CVPR2021)]

**Stylized Neural Painting.**[[PDF](https://arxiv.org/abs/2011.08114)] [[Project](https://jiupinjia.github.io/neuralpainter/)] [[Github](https://github.com/jiupinjia/stylized-neural-painting)]<br>
*Zhengxia Zou, Tianyang Shi, Shuang Qiu, Yi Yuan, Zhenwei Shi.*<br>

**CoCosNet V2: Full-Resolution Correspondence Learning for Image Translation.**[[PDF](https://arxiv.org/abs/2012.02047)]<br>
*Xingran Zhou, Bo Zhang, Ting Zhang, Pan Zhang, Jianmin Bao, Dong Chen, Zhongfei Zhang, Fang Wen.*<br>                

**Unpaired Image-to-Image Translation Via Latent Energy Transport.**[[PDF](https://arxiv.org/abs/2012.00649)]<br>
*Yang Zhao, Changyou Chen.*<br>                

**Encoding in Style: A StyleGAN Encoder for Image-to-Image Translation.**[[PDF](https://arxiv.org/abs/2008.00951)]<br>
*Elad Richardson, Yuval Alaluf, Or Patashnik, Yotam Nitzan, Yaniv Azar, Stav Shapiro, Daniel Cohen-Or.*<br>                

**Saliency-Guided Image Translation.**[[PDF](https://openaccess.thecvf.com/content/CVPR2021/papers/Jiang_Saliency-Guided_Image_Translation_CVPR_2021_paper.pdf)]<br>
*Lai Jiang, Mai Xu, Xiaofei Wang, Leonid Sigal.*<br>

**Model-Aware Gesture-to-Gesture Translation.**[[PDF](https://openaccess.thecvf.com/content/CVPR2021/papers/Hu_Model-Aware_Gesture-to-Gesture_Translation_CVPR_2021_paper.pdf)]<br>
*Hezhen Hu, Weilun Wang, Wengang Zhou, Weichao Zhao, Houqiang Li.*<br>

**Closing the Loop: Joint Rain Generation and Removal via Disentangled Image Translation.**[[PDF](http://arxiv.org/abs/2103.13660)]<br>
*Yuntong Ye, Yi Chang, Hanyu Zhou, Luxin Yan.*<br>

**Not Just Compete, but Collaborate: Local Image-to-Image Translation via Cooperative Mask Prediction.**[[PDF](https://openaccess.thecvf.com/content/CVPR2021/papers/Kim_Not_Just_Compete_but_Collaborate_Local_Image-to-Image_Translation_via_Cooperative_CVPR_2021_paper.pdf)]<br>
*Daejin Kim, Mohammad Azam Khan, Jaegul Choo.*<br>

**The Spatially-Correlative Loss for Various Image Translation Tasks.**[[PDF](http://arxiv.org/abs/2104.00854)][[Github](https://github.com/lyndonzheng/F-LSeSim)][[Project](http://www.chuanxiaz.com/publication/flsesim/)]<br> 
*[Chuanxia Zheng](http://www.chuanxiaz.com/), [Tat-Jen Cham](http://www.ntu.edu.sg/home/astjcham/), [Jianfei Cai](https://research.monash.edu/en/persons/jianfei-cai).*<br>

**LPTN: High-Resolution Photorealistic Image Translation in Real-Time: A Laplacian Pyramid Translation Network.**[[PDF](https://arxiv.org/abs/2105.09188)] [[Github](https://github.com/csjliang/LPTN)]<br>
*Jie Liang, Hui Zeng, Lei Zhang.*<br>

**Unbalanced Feature Transport for Exemplar-based Image Translation.**[[PDF](https://arxiv.org/abs/2106.10482)][[Github](https://github.com/fnzhan/UNITE)]<br> 
*Fangneng Zhan, Yingchen Yu, Kaiwen Cui, Gongjie Zhang, Shijian Lu, Jianxiong Pan, Changgong Zhang, Feiying Ma, Xuansong Xie, Chunyan Miao.*<br>

**CoCosNet v2: Full-Resolution Correspondence Learning for Image Translation.**[[PDF](https://arxiv.org/abs/2012.02047)][[Github](https://github.com/microsoft/CoCosNet-v2)] <br> 
*[Xingran Zhou](http://xingranzh.github.io/), [Bo Zhang](https://bo-zhang.me/), [Ting Zhang](https://www.microsoft.com/en-us/research/people/tinzhan/), [Pan Zhang](https://panzhang0212.github.io/), [Jianmin Bao](https://jianminbao.github.io/), [Dong Chen](https://www.microsoft.com/en-us/research/people/doch/), [Zhongfei Zhang](https://www.cs.binghamton.edu/~zhongfei/), [Fang Wen](https://www.microsoft.com/en-us/research/people/fangwen/).*<br>

**Few-shot Image Generation via Cross-domain Correspondence.**[[PDF](https://arxiv.org/abs/2104.06820)] [[Project](https://utkarshojha.github.io/few-shot-gan-adaptation/)] [[Github](https://github.com/utkarshojha/few-shot-gan-adaptation)] <br>
*Utkarsh Ojha, Yijun Li, Jingwan Lu, Alexei A. Efros, Yong Jae Lee, Eli Shechtman, Richard Zhang.*<br>

**Encoding in Style: a StyleGAN Encoder for Image-to-Image Translation.**[[PDF](https://arxiv.org/abs/2008.00951)] [[Github](https://github.com/eladrich/pixel2style2pixel)] [[Project](eladrich.github.io/pixel2style2pixel/)]<br>
*Elad Richardson, Yuval Alaluf, Or Patashnik, Yotam Nitzan, Yaniv Azar, Stav Shapiro, Daniel Cohen-Or.*<br>

**Memory-guided Unsupervised Image-to-image Translation.[[PDF](https://arxiv.org/abs/2104.05170)]**<br> 
*Somi Jeong, Youngjung Kim, Eungbean Lee, Kwanghoon Sohn.*<br>

**Smoothing the Disentangled Latent Style Space for Unsupervised Image-to-Image Translation.[[PDF](https://openaccess.thecvf.com/content/CVPR2021/papers/Liu_Smoothing_the_Disentangled_Latent_Style_Space_for_Unsupervised_Image-to-Image_Translation_CVPR_2021_paper.pdf)]**<br>
*Yahui Liu, Enver Sangineto, Yajing Chen, Linchao Bao, Haoxian Zhang, Nicu Sebe, Bruno Lepri, Wei Wang, Marco De Nadai.*<br>

**ReMix: Towards Image-to-Image Translation with Limited Data.[[PDF](https://arxiv.org/pdf/2103.16835.pdf)]**<br> 
*Jie Cao, Luanxuan Hou, Ming-Hsuan Yang, Ran He, Zhenan Sun.*<br>

**DivCo: Diverse Conditional Image Synthesis via Contrastive Generative Adversarial Network.**[[PDF](https://arxiv.org/pdf/2103.07893.pdf)] [[GitHub](https://github.com/ruiliu-ai/DivCo)]<br> 
*Rui Liu, Yixiao Ge, Ching Lam Choi, Xiaogang Wang, Hongsheng Li.*<br>

**(oral) CoMoGAN: Continuous Model-guided Image-to-image Translation.**[[PDF](https://arxiv.org/abs/2103.06879)] [[GitHub](https://github.com/cv-rits/CoMoGAN)]<br>
*[Fabio Pizzati](https://fabvio.github.io/), [Pietro Cerri](https://scholar.google.fr/citations?user=MEidJHwAAAAJ), [Raoul de Charette](https://team.inria.fr/rits/membres/raoul-de-charette/).*<br>

**PISE: Person Image Synthesis and Editing with Decoupled GAN.**[[PDF](https://arxiv.org/abs/2103.04023)] [[Project](http://cic.tju.edu.cn/faculty/likun/projects/PISE/)] [[Github](https://github.com/Zhangjinso/PISE)]<br>
*[Jinsong Zhang](https://zhangjinso.github.io/), [Kun Li](http://cic.tju.edu.cn/faculty/likun/), [Yu-Kun Lai](http://users.cs.cf.ac.uk/Yukun.Lai/), [Jingyu Yang](http://tju.iirlab.org/).*<br>

**ASAPNet: Spatially-Adaptive Pixelwise Networks for Fast Image Translation.**[[PDF](https://arxiv.org/abs/2012.02992)] [[Project](https://tamarott.github.io/ASAPNet_web/)]<br>
*[Tamar Rott Shaham](https://tamarott.github.io/), [Michael Gharbi](http://www.mgharbi.com/), Richard Zhang, Eli Shechtman, Tomer Michaeli.*<br>

**(oral) HiSD: Image-to-image Translation via Hierarchical Style Disentanglement.**[[PDF](https://arxiv.org/abs/2103.01456)] [[Github](https://github.com/imlixinyang/HiSD)]<br>
*Xinyang Li, Shengchuan Zhang, Jie Hu, Liujuan Cao, Xiaopeng Hong, Xudong Mao, Feiyue Huang, Yongjian Wu, Rongrong Ji.*<br>

**Teachers Do More Than Teach: Compressing Image-to-Image Models.**[[PDF](https://arxiv.org/abs/2103.03467)][[Github](https://github.com/snap-research/CAT)]<br> 
*Qing Jin, Jian Ren, Oliver J. Woodford, Jiazhuo Wang, Geng Yuan, Yanzhi Wang, Sergey Tulyakov.*<br>

### ICLR 2021

[[accepted paper list](https://openreview.net/group?id=ICLR.cc/2021/Conference)]

**DINO: A Conditional Energy-Based GAN for Domain Translation.**[[PDF](https://arxiv.org/abs/2102.09281)] [[GitHub](https://github.com/DinoMan/DINO)]<br>
*Konstantinos Vougioukas, Stavros Petridis, Maja Pantic.*<br>

**Enjoy Your Editing: Controllable GANs for Image Editing via Latent Space Navigation.**[[PDF](https://arxiv.org/abs/2102.01187)]<br>
*Peiye Zhuang, Oluwasanmi Koyejo, Alexander G. Schwing.*<br>

### Others 2021

**UNIT-DDPM: UNpaired Image Translation with Denoising Diffusion Probabilistic Models.**<br>
*Hiroshi Sasaki, Chris G. Willcocks, Toby P. Breckon.*<br>                
arxiv 2021. [[PDF](https://arxiv.org/abs/2104.05358)]

**A Novel Framework for Image-to-image Translation and Image Compression.**<br>
*Fei Yang, Yaxing Wang, Luis Herranz, Yongmei Cheng, Mikhail Mozerov.*<br>                
arxiv 2021. [[PDF](https://arxiv.org/abs/2111.13105)]

**Global and Local Alignment Networks for Unpaired Image-to-Image Translation.**<br>
*Guanglei Yang, Hao Tang, Humphrey Shi, Mingli Ding, Nicu Sebe, Radu Timofte, Luc Van Gool, Elisa Ricci.*<br>                
arxiv 2021. [[PDF](https://arxiv.org/pdf/2111.10346.pdf)] [[Github](https://github.com/ygjwd12345/GLANet)]

**LSC-GAN: Latent Style Code Modeling for Continuous Image-to-image Translation.**<br>
*Qiusheng Huang, Xueqi Hu, Li Sun, Qingli Li.*<br>                
arxiv 2021. [[PDF](https://arxiv.org/abs/2110.05052)]

**Translating Images Into Maps.**<br>
*Avishkar Saha, Oscar Mendez Maldonado, Chris Russell, Richard Bowden.*<br>                
arxiv 2021. [[PDF](https://arxiv.org/abs/2110.00966)] [[Github](https://github.com/avishkarsaha/translating-images-into-maps)]

**Leveraging Local Domains for Image-to-Image Translation.**<br>
*Anthony Dell'Eva, Fabio Pizzati, Massimo Bertozzi, Raoul de Charette.*<br>                
arxiv 2021. [[PDF](https://arxiv.org/abs/2109.04468)]

**ISF-GAN: An Implicit Style Function for High-Resolution Image-to-Image Translation.**<br>
*Yahui Liu, Yajing Chen, Linchao Bao, Nicu Sebe, Bruno Lepri, Marco De Nadai.*<br>                
arxiv 2021. [[PDF](https://arxiv.org/abs/2109.12492)] [[Github](https://github.com/yhlleo/stylegan-mmuit)]

**AniGAN: Style-Guided Generative Adversarial Networks for Unsupervised Anime Face Generation.**<br>
*Bing Li, Yuanlue Zhu, Yitong Wang, Chia-Wen Lin, Bernard Ghanem, Linlin Shen.*<br>                
arxiv 2021. [[PDF](https://arxiv.org/abs/2102.12593)] [[Github](https://github.com/bing-li-ai/AniGAN)]

**Image-to-Image Translation with Low Resolution Conditioning.**<br>
*Mohamed Abderrahmen Abid, Ihsen Hedhli, Jean-François Lalonde, Christian Gagne.*<br>                
arxiv 2021. [[PDF](https://arxiv.org/abs/2107.11262)]

**Independent Encoder for Deep Hierarchical Unsupervised Image-to-Image Translation.**<br>
*Kai Ye, Yinru Ye, Minqiang Yang, Bin Hu.*<br>                
arxiv 2021. [[PDF](https://arxiv.org/abs/2107.02494)] [[Github](https://github.com/Elvinky/IEGAN)]

**Federated CycleGAN for Privacy-Preserving Image-to-Image Translation.**<br>
*Joonyoung Song, Jong Chul Ye.*<br>                
arxiv 2021. [[PDF](https://arxiv.org/abs/2106.09246)]

**MixerGAN: An MLP-Based Architecture for Unpaired Image-to-Image Translation.**<br>
*George Cazenavette, Manuel Ladron De Guevara.*<br>                
arxiv 2021. [[PDF](https://arxiv.org/abs/2105.14110)]

**Guided Image Generation with Conditional Invertible Neural Networks.**<br>
*Lynton Ardizzone, Carsten Lüth, Jakob Kruse, Carsten Rother, Ullrich Köthe.*<br>                
arxiv 2021. [[PDF](https://arxiv.org/abs/1907.02392)]

**Contrastive Learning for Unsupervised Image-to-Image Translation.**<br>
*Hanbit Lee, Jinseok Seol, Sang-goo Lee.*<br>                
arxiv 2021. [[PDF](https://arxiv.org/abs/2105.03117)]

**A Novel Application of Image-to-Image Translation: Chromosome Straightening Framework by Learning from A Single Image.**<br>
*Sifan Song, Daiyun Huang, Yalun Hu, Chunxiao Yang, Jia Meng, Fei Ma, Frans Coenen, Jiaming Zhang, Jionglong Su.*<br>                
arxiv 2021. [[PDF](https://arxiv.org/abs/2103.02835)]

**Image-to-Image Translation: Methods and Applications.**<br>
*Yingxue Pang, Jianxin Lin, Tao Qin, Zhibo Chen.*<br>                
arxiv 2021. [[PDF](https://arxiv.org/abs/2101.08629)]

**Few-shot Semantic Image Synthesis Using StyleGAN Prior.**<br>
*Yuki Endo, Yoshihiro Kanamori.*<br>                
arxiv 2021. [[PDF](https://arxiv.org/abs/2103.14877)] [[Github](https://github.com/endo-yuki-t/Fewshot-SMIS)]

**Deep Sketch-guided Cartoon Video Inbetweening.**<br>
*Xiaoyu Li, Bo Zhang, Jing Liao, Pedro V. Sander.*<br>                
TVCG 2021. [[PDF](https://arxiv.org/abs/2008.04149)] [[Github](https://github.com/xiaoyu258/Inbetweening)]

**Neural Photometry-guided Visual Attribute Transfer.**<br>
*[Carlos Rodriguez-Pardo](https://carlosrodriguezpardo.es/), Elena Garces*<br>
TVCG 2021. [[PDF](https://arxiv.org/abs/2112.02520)] [[Project](https://carlosrodriguezpardo.es/projects/NeuralPhotometricTransfer/)] [[Video](https://youtu.be/9Cfi9DDenGc)] 

**MangaGAN: Unpaired Photo-to-Manga Translation Based on The Methodology of Manga Drawing.**<br>
*Hao Su, Jianwei Niu, Xuefeng Liu, Qingfeng Li, Jiahe Cui, Ji Wan.*<br>                
AAAI 2021. [[PDF](https://arxiv.org/abs/2004.10634)]

**BlendGAN: Implicitly GAN Blending for Arbitrary Stylized Face Generation.**<br>
*[Mingcong Liu](https://scholar.google.com/citations?user=IYx0IbgAAAAJ), [Qiang Li](https://scholar.google.com/citations?user=GGPvOP4AAAAJ), [Zekui Qin](https://github.com/ZekuiQin), [Guoxin Zhang](), [Pengfei Wan](), [Wen Zheng](https://sites.google.com/view/zhengwen-kwai).*<br>
NeurIPS 2021. [[PDF](https://arxiv.org/abs/2110.11728)] [[Github](https://github.com/onion-liu/BlendGAN)]

**Stochastic Actor-Executor-Critic for Image-to-Image Translation.**<br> 
*Ziwei Luo, Jing Hu, Xin Wang, Siwei Lyu, Bin Kong, Youbing Yin, Qi Song, Xi Wu.*<br> 
IJCAI 2021. [[PDF](https://arxiv.org/abs/2112.07403)]

**Semantic Map Injected GAN Training for Image-to-Image Translation.**<br> 
*Balaram Singh Kshatriya, Shiv Ram Dubey, Himangshu Sarma, Kunal Chaudhary, Meva Ram Gurjar, Rahul Rai, Sunny Manchanda.*<br> 
WCVA 2021 Workshop at ICVGIP. [[PDF](https://arxiv.org/abs/2112.01845)]

**Gated SwitchGAN for multi-domain facial image translation.**<br> 
*Xiaokang Zhang, Yuanlue Zhu, Wenting Chen, Wenshuang Liu, Linlin Shen.*<br> 
TMM 2021. [[PDF](https://arxiv.org/abs/2111.14096)]

**Breaking the Dilemma of Medical Image-to-image Translation.**<br>
*Lingke Kong, Chenyu Lian, Detian Huang, Zhenjiang Li, Yanle Hu, Qichao Zhou.*<br> 
NeurIPS 2021. [[PDF](https://arxiv.org/pdf/2110.06465.pdf)] [[Github](https://github.com/Kid-Liet/Reg-GAN)]

**A Domain Gap Aware Generative AdversarialNetwork for Multi-domain Image Translation.**<br>
*Wenju Xu, Guanghui Wang.*<br>
TIP 2021. [[PDF](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9612090)] 

**SuperStyleNet: Deep Image Synthesis with Superpixel Based Style Encoder.**<br>
*Jonghuyn Kim, Gen Li, Cheolkon Jung, Joongkyu Kim.*<br>
BMVC 2021. [[PDF](https://arxiv.org/abs/2112.09367)] [[Github](https://github.com/BenjaminJonghyun/SuperStyleNet)]

**Cascaded Cross MLP-Mixer GANs for Cross-View Image Translation.**<br>
*Bin Ren, Hao Tang, Nicu Sebe.*<br>
BMVC 2021 (Oral). [[PDF](https://arxiv.org/abs/2110.10183)] [[Github](https://github.com/Amazingren/CrossMLP)]

**Separating Content and Style for Unsupervised Image-to-Image Translation.**<br>
*Yunfei Liu, Haofei Wang, Yang Yue, Feng Lu.*<br>
BMVC 2021 (Oral). [[PDF](https://arxiv.org/abs/2110.14404)]

**Graph2Pix: A Graph-Based Image to Image Translation Framework.**<br>
*Dilara Gokay, Enis Simsar, Efehan Atici, Alper Ahmetoglu, Atif Emre Yuksel, Pinar Yanardag.*<br>
ICCV 2021 Workshop on AIM. [[PDF](http://arxiv.org/abs/2108.09752)]  [[Github](https://github.com/catlab-team/graph2pix)]

**Unsupervised Generative Adversarial Networks With Cross-Model Weight Transfer Mechanism for Image-to-Image Translation.**<br>
*Xuguang Lai, Xiuxiu Bai, Yongqiang Hao.*<br>
ICCV Workshop 2021. [[PDF](https://www.alexandonian.com/pdf/Contrastive_Feature_Loss.pdf)]

**Contrastive Feature Loss for Image Prediction.**<br>
*[Alex Andonian](https://www.alexandonian.com/), Taesung Park, Bryan Russell, Phillip Isola, Jun-Yan Zhu, Richard Zhang.*<br>
ICCV Workshop 2021. [[PDF](https://www.alexandonian.com/pdf/Contrastive_Feature_Loss.pdf)]

**Bridging the Gap Between Paired and Unpaired Medical Image Translation.**<br>
*Pauliina Paavilainen, Saad Ullah Akram, Juho Kannala.*<br>
MICCI Workshop 2021. [[PDF](https://link.springer.com/chapter/10.1007/978-3-030-88210-5_4)]

**I2V-GAN: Unpaired Infrared-to-Visible Video Translation.**<br>
*Shuang Li, Bingfeng Han, Zhenjie Yu, Chi Harold Liu, Kai Chen, Shuigen Wang.*<br>
ACM MM 2021. [[PDF](https://arxiv.org/abs/2108.00913)] [[Github](https://github.com/BIT-DA/I2V-GAN)]

**BalaGAN: Image Translation Between Imbalanced Domains via Cross-Modal Transfer.**<br>
*Or Patashnik, Dov Danon, Hao Zhang, Daniel Cohen-Or.*<br>
CVPR 2021 Workshop. [[PDF](https://arxiv.org/abs/2010.02036)] [[Project](https://orpatashnik.github.io/BalaGAN/)] [[Github](https://github.com/orpatashnik/BalaGAN)]

**Dual Contrastive Learning for Unsupervised Image-to-Image Translation.**<br>
*Junlin Han, Mehrdad Shoeiby, Lars Petersson, Mohammad Ali Armin.*<br>
CVPR 2021 Workshop on NTIRE. [[PDF](https://arxiv.org/abs/2104.07689)] [[Github](https://github.com/JunlinHan/DCLGAN)]

**SAM: Only a Matter of Style-Age Transformation Using a Style-Based Regression Model.**<br>
*Yuval Alaluf, Or Patashnik, [Daniel Cohen-Or](https://www.cs.tau.ac.il/~dcor/).*<br>
TOG 2021. [[PDF](https://arxiv.org/abs/2102.02754)] [[Github](https://github.com/yuval-alaluf/SAM)]

**iFlowGAN: An Invertible Flow-based Generative Adversarial Network For Unsupervised Image-to-Image Translation.**<br>
*[Longquan Dai](https://dailongquan.github.io/), [Jinhui Tang](https://imag-njust.net/jinhui-tang/).*<br>
TPAMI 2021. [[PDF](https://www.computer.org/csdl/journal/tp/5555/01/09367012/1rDQXw8mKnC)]

**Complementary, Heterogeneous and Adversarial Networks for Image-to-Image Translation.**<br>
*[Fei Gao](http://aiart.live/), Xingxin Xu, Jun Yu, Meimei Shang, Xiang Li, and Dacheng Tao.*<br>
TIP 2021. [[PDF](https://ieeexplore.ieee.org/document/9366371)] [[Project](https://fei-hdu.github.io/chan/)]

**Multi-Domain Image-to-Image Translation with Adaptive Inference Graph.**<br>
*The-Phuc Nguyen, Stéphane Lathuilière, Elisa Ricci.*<br>
ICPR 2021. [[PDF](https://arxiv.org/abs/2101.03806)]

**Attention-Based Spatial Guidance for Image-to-Image Translation.**<br>
*Yu Lin, Yigong Wang, Yifan Li, Yang Gao, Zhuoyi Wang, Latifur Khan.*<br>
WACV 2021. [[PDF](https://openaccess.thecvf.com/content/WACV2021/html/Lin_Attention-Based_Spatial_Guidance_for_Image-to-Image_Translation_WACV_2021_paper.html)]

**DCN: Zero-Pair Image to Image Translation using Domain Conditional Normalization.**<br>
*Samarth Shukla, Andrés Romero, Luc Van Gool, Radu Timofte.*<br>
WACV 2021. [[PDF](https://arxiv.org/abs/2011.05680)] [[Project](https://github.com/samarthshukla/dcn)]

**Analogical Image Translation for Fog Generation.**</br>
*Rui Gong, Dengxin Dai, [Yuhua Chen](https://yuhuayc.github.io/), Wen Li, Luc Van Gool.*</br>
AAAI 2021. [[PDF](https://arxiv.org/abs/2006.15618)]

**TriGAN: Image-to-Image Translation for Multi-Source Domain Adaptation.**<br>
*Subhankar Roy, Aliaksandr Siarohin, Enver Sangineto, Nicu Sebe, Elisa Ricci.*<br>
Springer Machine Vision and Applications 2021. [[PDF](https://arxiv.org/abs/2004.08769)]

## 2020

### ECCV 2020
[[accepted paper list](https://eccv2020.eu/accepted-papers/)]

**Self-Supervised CycleGAN for Object-Preserving Image-to-Image Domain Adaptation.**[[PDF](https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123650494.pdf)]<br>
*Xinpeng Xie, Jiawei Chen, Yuexiang Li, Linlin Shen, Kai Ma, Yefeng Zheng.*<br>  

**World-Consistent Video-to-Video Synthesis.**[[PDF](https://arxiv.org/abs/2007.08509)] [[Github](https://nvlabs.github.io/wc-vid2vid/)]<br> 
*Arun Mallya, Ting-Chun Wang, Karan Sapra, Ming-Yu Liu.*<br>  

**CUT: Contrastive Learning for Unpaired Image-to-Image Translation.**[[PDF](https://arxiv.org/abs/2007.15651)] [[Project](https://taesungp.github.io/ContrastiveUnpairedTranslation/)] [[Github](https://github.com/taesungp/contrastive-unpaired-translation)]<br>
*[Taesung Park](https://taesungp.github.io), Alexei A. Efros, Richard Zhang, Jun-Yan Zhu.*<br> 

**Unselfie: Translating Selfies to Neutral-pose Portraits in the Wild.**[[PDF](https://homes.esat.kuleuven.be/~liqianma/pdf/ECCV20_Unselfie.pdf)] <br>
*[Liqian Ma](https://homes.esat.kuleuven.be/~liqianma), Zhe Lin, Connelly Barnes, Alexei A. Efros, Jingwan Lu.*<br>

**TSIT: A Simple and Versatile Framework for Image-to-Image Translation.**[[PDF](https://arxiv.org/abs/2007.12072)][[Github](https://github.com/EndlessSora/TSIT)]<br>
*[Liming Jiang](https://liming-jiang.com/), [Changxu Zhang](http://zhangcx.top/), Mingyang Huang, Chunxiao Liu, Jianping Shi, [Chen Change Loy](http://personal.ie.cuhk.edu.hk/~ccloy/).*<br>

**LEED: Label-Free Expression Editing via Disentanglement.**[[PDF](https://arxiv.org/abs/2007.08971)]<br>
*Rongliang Wu, Shijian Lu.*<br> 

**Unsupervised Sketch-to-Photo Synthesis.**[[PDF](https://arxiv.org/abs/1909.08313)][[Github](https://github.com/rt219/Unpaired-Sketch-to-Photo-Translation)]<br> 
*Runtao Liu, Qian Yu, Stella Yu.*<br>

**Transformation Consistency Regularization: A Semi-Supervised Paradigm for Image-to-Image Translation.**[[PDF](https://arxiv.org/abs/2007.07867)]<br>
*Aamir Mustafa, Rafal K. Mantiuk.*<br>

**Cross-Domain Cascaded Deep Feature Translation.**[[PDF](https://arxiv.org/abs/1906.01526)]<br>
*Oren Katzir, Dani Lischinski, Daniel Cohen-Or.*<br>

**Unpaired Image-to-Image Translation using Adversarial Consistency Loss.**[[PDF](https://arxiv.org/abs/2003.04858)]<br>
*Yihao Zhao, Ruihai Wu, Hao Dong.*<br>

**COCO-FUNIT: Few-Shot Unsupervised Image Translation with a Content Conditioned Style Encoder.**[[PDF](https://arxiv.org/abs/2007.07431)][[Github](https://nvlabs.github.io/COCO-FUNIT/)][[Project](https://nvlabs.github.io/COCO-FUNIT/)]<br>
*[Kuniaki Saito](http://cs-people.bu.edu/keisaito/), [Kate Saenko](http://ai.bu.edu/ksaenko.html), [Ming-Yu Liu](http://mingyuliu.net/).*<br>

**XingGAN for Person Image Generation.**[[Github](https://github.com/Ha0Tang/XingGAN)]<br>
*[Hao Tang](http://disi.unitn.it/~hao.tang/), Song Bai, Li Zhang, Philip H. S. Torr, Nicu Sebe.*<br>

**GANHopper: Multi-Hop GAN for Unsupervised Image-to-Image Translation.**[[PDF](https://arxiv.org/abs/2002.10102)]<br>
*Wallace Lira, Johannes Merz, Daniel Ritchie, Daniel Cohen-Or, Hao Zhang.*<br>

**TuiGAN: Learning Versatile Image-to-Image Translation with Two Unpaired Images.**[[PDF](https://arxiv.org/abs/2004.04634)] [[Github](https://github.com/linjx-ustc1106/TuiGAN-PyTorch)]<br>
*Jianxin Lin, Yingxue Pang, Yingce Xia, Zhibo Chen, Jiebo Luo.*<br>

**Model-based Occlusion Disentanglement for Image-to-image Translation.**[[PDF]](https://arxiv.org/abs/2004.01071)<br>
*[Fabio Pizzati](https://fabvio.github.io), Pietro Cerri, Raoul de Charette.*<br>

**Semantic Relation Preserving Knowledge Distillation for Image-to-Image Translation.**[[pdf](https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123710647.pdf)] [[Supplement](https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123710647-supp.pdf)]<br>
*Zeqi Li, Ruowei Jiang,, Parham Aarabi.*<br> 

**Informative Sample Mining Network for Multi-Domain Image-to-Image Translation.**[[pdf](https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123640392.pdf)] [[Supplement](https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123640392-supp.pdf)]<br>
*Jie Cao, Huaibo Huang, Yi Li, Ran He, Zhenan Sun.*<br> 

**Neural Wireframe Renderer: Learning Wireframe to Image Translations.**[[pdf](https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123710273.pdf)] [[Github](https://github.com/YuanXue1993/WireframeRenderer)] [[Supplement](https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123710273-supp.pdf)]<br>
*Yuan Xue, [Zihan Zhou](http://faculty.ist.psu.edu/zzhou/Home.html), Xiaolei Huang.*<br> 

**ForkGAN: Seeing into the Rainy Night.**[[PDF](https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123480154.pdf)]
*Ziqiang Zheng, Yang Wu, Xinran Han, Jianbo Shi.*<br> 

### CVPR 2020
[[accepted paper list](https://openaccess.thecvf.com/CVPR2020)]

**Learning to Cartoonize Using White-box Cartoon Representations.**[[PDF](https://systemerrorwang.github.io/White-box-Cartoonization/paper/06791.pdf)][[Github](https://github.com/SystemErrorWang/White-box-Cartoonization)][[Project](https://systemerrorwang.github.io/White-box-Cartoonization/)]<br>
*Xinrui Wang and Jinze Yu.*<br>  

**Attentive Normalization for Conditional Image Generation.**[[PDF](https://arxiv.org/abs/2004.03828)]<br>
*Yi Wang, Ying-Cong Chen, Xiangyu Zhang, Jian Sun, Jiaya Jia.*<br>

**Diverse Image Generation via Self-Conditioned GANs.**.[[PDF](https://arxiv.org/abs/2006.10728)] [[Project](http://selfcondgan.csail.mit.edu/)] [[Github](https://github.com/stevliu/self-conditioned-gan)] <br>
*Steven Liu, Tongzhou Wang, David Bau, Jun-Yan Zhu, Antonio Torralba.*<br>

**Fine-grained Image-to-Image Transformation towards Visual Recognition.** [[PDF](https://arxiv.org/abs/2001.03856)] <br>
*Wei Xiong, Yutong He, Yixuan Zhang, Wenhan Luo, Lin Ma, Jiebo Luo.*<br>

**RL-CycleGAN: Reinforcement Learning Aware Simulation-To-Real.** [[PDF](https://arxiv.org/abs/2006.09001)] <br>
*Kanishka Rao, Chris Harris, Alex Irpan, Sergey Levine, Julian Ibarz, Mohi Khansari.*<br>

**CouncilGAN: Breaking The Cycle: Colleagues Are All You Need.**[[PDF](https://arxiv.org/abs/1911.10538)][[Project](https://onr.github.io/Council_web/)][[Github](https://github.com/Onr/Council-GAN)]<br>
*[Ori Nizan](https://onr.github.io/), [Ayellet Tal](https://webee.technion.ac.il/~ayellet/).*<br>

**DUNIT: Detection-based Unsupervised Image-to-Image Translation.**[[PDF](https://seungryong.github.io/publication/DUNIT_CVPR2020)]<br>
*Deblina Bhattacharjee, [Seungryong Kim](https://seungryong.github.io), Guillaume Vizier, and Mathieu Salzmann.*<br>

**UCTGAN: Diverse Image Inpainting Based on Unsupervised Cross-Space Translation.**[[PDF](http://openaccess.thecvf.com/content_CVPR_2020/papers/Zhao_UCTGAN_Diverse_Image_Inpainting_Based_on_Unsupervised_Cross-Space_Translation_CVPR_2020_paper.pdf)]<br>
*Lei Zhao, Qihang Mo, Sihuan Lin, Zhizhong Wang, Zhiwen Zuo, Haibo Chen, Wei Xing, Dongming Lu.*<br>

**Wish You Were Here: Context-Aware Human Generation.**[[PDF](https://arxiv.org/abs/2005.10663)]<br>
*Oran Gafni, Lior Wolf.*<br>

**Deformation-aware Unpaired Image Translation for Pose Estimation on Laboratory Animals.**[[PDF](https://arxiv.org/abs/2001.08601)]<br>
*Siyuan Li, [Semih Günel](https://semihgunel.com/), Mirela Ostrek, Pavan Ramdya, [Pascal Fua](https://people.epfl.ch/pascal.fua/bio?lang=en), [Helge Rhodin](http://helge.rhodin.de/).*<br>

**Unsupervised Multi-Modal Image Registration via Geometry Preserving Image-to-Image Translation.** [[PDF](http://openaccess.thecvf.com/content_CVPR_2020/papers/Arar_Unsupervised_Multi-Modal_Image_Registration_via_Geometry_Preserving_Image-to-Image_Translation_CVPR_2020_paper.pdf)] <br>
*Moab Arar, Yiftach Ginger, Dov Danon, Amit H. Bermano, Daniel Cohen-Or.*<br>

**Bringing Old Photos Back to Life.**[[PDF](https://arxiv.org/abs/2004.09484)] [[Github](https://github.com/microsoft/Bringing-Old-Photos-Back-to-Life)] [[Project](http://raywzy.com/Old_Photo/)]<br>
*[Ziyu Wan](http://raywzy.com), Bo Zhang, [Dongdong Chen](http://www.dongdongchen.bid/), Pan Zhang, Dong Chen, Jing Liao, Fan Wen.*<br>

**Reference-Based Sketch Image Colorization using Augmented-Self Reference and Dense Semantic Correspondence.**[[PDF](https://arxiv.org/abs/2005.05207)]<br>
*Junsoo Lee, Eungyeup Kim, Yunsung Lee, Dongjun Kim, Jaehyuk Chang, Jaegul Choo.*<br>

**SMIS: Semantically Multi-modal Image Synthesis.**[[PDF](https://arxiv.org/abs/2003.12697)] [[Project](http://seanseattle.github.io/SMIS)] [[Github](https://github.com/Seanseattle/SMIS)]<br> 
*[Zhen Zhu](https://zzhu.vision/), Zhiliang Xu, Ansheng You, [Xiang Bai](http://cloud.eic.hust.edu.cn:8071/~xbai/).*<br>

**SEAN: Image Synthesis with Semantic Region-Adaptive Normalization.**[[PDF](https://arxiv.org/abs/1911.12861)] [[Video](https://youtu.be/0Vbj9xFgoUw)] [[Github](https://github.com/ZPdesu/SEAN)]</br>
*Peihao Zhu, Rameen Abdal, Yipeng Qin, Peter Wonka.*<br> 

**CoCosNet: Cross-domain Correspondence Learning for Exemplar-based Image Translation.**[[PDF](https://arxiv.org/abs/2004.05571)][[Project](https://panzhang0212.github.io/CoCosNet/)] [[Unofficial](https://github.com/Lotayou/CoCosNet)] <br>
*[Pan Zhang](panzhang0212.github.io), [Bo Zhang](https://www.microsoft.com/en-us/research/people/zhanbo/), Dong Chen, Lu Yuan, Fang Wen.*<br>
<details>
  <summary> Comment </summary>
  CoCosNet = <a href="http://openaccess.thecvf.com/content_CVPR_2019/papers/Zhang_Deep_Exemplar-Based_Video_Colorization_CVPR_2019_paper">DEVC</a> + <a href="https://github.com/NVlabs/SPADE">SPADE</a>
</details>

**STEFANN: Scene Text Editor using Font Adaptive Neural Network.**[[PDF](https://prasunroy.github.io/stefann/static/docs/08915.pdf)] [[Project](https://prasunroy.github.io/stefann/)] [[Github](https://github.com/prasunroy/stefann)] [[Data](https://drive.google.com/open?id=1sEDiX_jORh2X-HSzUnjIyZr-G9LJIw1k)]<br> 
*Prasun Roy, Saumik Bhattacharya, Subhankar Ghosh, Umapada Pal.*<br>

**Intuitive, Interactive Beard and Hair Synthesis with Generative Models.**[[PDF](https://arxiv.org/abs/2004.06848)]<br>
*Kyle Olszewski, Duygu Ceylan, Jun Xing, Jose Echevarria, Zhili Chen, Weikai Chen, Hao Li.*<br>

**Semantic Image Manipulation Using Scene Graphs.**[[PDF](https://arxiv.org/abs/2004.03677)]<br>
*Helisa Dhamo, Azade Farshad, Iro Laina, Nassir Navab, Gregory D. Hager, Federico Tombari, Christian Rupprecht.*<br>

**Domain Adaptive Image-to-image Translation.**[[PDF](https://jiaya.me/papers/dai2i_cvpr20.pdf)]<br>
*[Ying-Cong Chen](https://yingcong.github.io/), Xiaogang Xu and Jiaya Jia.* <br>

**Attentive Normalization for Conditional Image Generation.**[[PDF](https://arxiv.org/abs/2004.03828)] <br>
*Yi Wang, [Ying-Cong Chen](https://yingcong.github.io/), Xiangyu Zhang, Jian Sun and Jiaya Jia.*<br>

**Guided Variational Autoencoder for Disentanglement Learning.**[[PDF](https://arxiv.org/abs/2004.01255)]<br>
*Zheng Ding, Yifan Xu, Weijian Xu, Gaurav Parmar, Yang Yang, Max Welling, Zhuowen Tu.*<br>

**SEMIT: Semi-supervised Learning for Few-shot Image-to-Image Translation.**[[PDF](https://arxiv.org/abs/2003.13853)] [[Github](https://github.com/yaxingwang/SEMIT)]<br>
*Yaxing Wang, Salman Khan, Abel Gonzalez-Garcia, Joost van de Weijer, Fahad Shahbaz Khan.*<br>

**Augmenting Colonoscopy using Extended and Directional CycleGAN for Lossy Image Translation.**[[PDF](https://arxiv.org/abs/2003.12473)]<br>
*Shawn Mathew, Saad Nadeem, Sruti Kumari, Arie Kaufman.*<br>

**ADGAN: Controllable Person Image Synthesis with Attribute-Decomposed GAN.**[[PDF](https://menyifang.github.io/projects/ADGAN/ADGAN_files/Paper_ADGAN_CVPR2020.pdf)] [[Project](https://menyifang.github.io/projects/ADGAN/ADGAN.html)]  [[Github](https://github.com/menyifang/ADGAN)]<br>
*[Yifang Men](https://menyifang.github.io/), [Yiming Mao](https://mtroym.github.io/), Yuning Jiang, Wei-Ying Ma, Zhouhui Lian.*<br>

**LGGAN: Local Class-Specific and Global Image-Level Generative Adversarial Networks for Semantic-Guided Scene Generation.** [[PDF](https://arxiv.org/abs/1912.12215)] [[Github](https://github.com/Ha0Tang/LGGAN)]<br> 
*[Hao Tang](http://disi.unitn.it/~hao.tang/), Dan Xu, Yan Yan, Philip H. S. Torr, Nicu Sebe.*<br> 

**StarGAN v2: Diverse Image Synthesis for Multiple Domains.**[[PDF](https://arxiv.org/abs/1912.01865)] [[GitHub](https://github.com/clovaai/stargan-v2)] [[Tensorflow](https://github.com/taki0112/StarGAN_v2-Tensorflow)] [[AFHQ Data](https://github.com/clovaai/stargan-v2)] <br> 
*Yunjey Choi, Youngjung Uh, Jaejun Yoo, Jung-Woo Ha. Clova AI Research, NAVER Corp.*<br> 

**GAN Compression: Efficient Architectures for Interactive Conditional GANs.**[[PDF](https://arxiv.org/abs/2003.08936)] [[Demo](https://tinyurl.com/r474uca)] [[Github](https://github.com/mit-han-lab/gan-compression/)]<br>
*[Muyang Li](https://lmxyy.me/), Ji Lin, Yaoyao Ding, Zhijian Liu, Jun-Yan Zhu, and [Song Han](https://songhan.mit.edu/).*<br>

**HiDT: High-Resolution Daytime Translation Without Domain Labels.**[[PDF](https://arxiv.org/abs/2003.08791)]<br>
*Ivan Anokhin, Pavel Solovev, Denis Korzhenkov, Alexey Kharlamov, Taras Khakhulin, Gleb Sterkin, Alexey Silvestrov, Sergey Nikolenko, Victor Lempitsky.*<br>

**NICE: Reusing Discriminators for Encoding: Towards Unsupervised Image-to-Image Translation.** [[PDF](https://arxiv.org/abs/2003.00273)] [[Github](https://github.com/alpc91/NICE-GAN-pytorch)]<br>
*Runfa Chen, Wenbing Huang, Binghui Huang, Fuchun Sun, Bin Fang.*<br>

### AAAI 2020 
[[accepted paper list](https://aaai.org/Conferences/AAAI-20/wp-content/uploads/2020/01/AAAI-20-Accepted-Paper-List.pdf)]

**Distilling Portable Generative Adversarial Networks for Image Translation.** [[PDF](https://arxiv.org/abs/2003.03519)] <br>
*Hanting Chen, Yunhe Wang, Han Shu, Changyuan Wen, Chunjing Xu, Boxin Shi, Chao Xu, Chang Xu.*<br>

**Fast and Robust Face-to-Parameter Translation for Game Character Auto-Creation.**[[PDF](https://arxiv.org/pdf/1909.01064.pdf)]<br>
*Tianyang Shi, Zhengxia Zou, Yi Yuan, Changjie Fan.*<br>

**Learning to Transfer: Unsupervised Domain Translation via Meta-Learning.**[[PDF](https://arxiv.org/abs/1906.00181)] [[Github](https://github.com/linjx-ustc1106/MT-GAN-PyTorch)]<br>
*Jianxin Lin, Yijun Wang, [Zhibo Chen](http://staff.ustc.edu.cn/~chenzhibo/publi.html), Tianyu He.*<br>

**Go From the General to the Particular: Multi-Domain Translation with Domain Transformation Networks.**[[PDF](https://arxiv.org/abs/1911.09912)]<br>
*Yong Wang, Longyue Wang, Shuming Shi, Victor Li, Zhaopeng Tu.*<br>

**Generating Diverse Translation by Manipulating Multi-Head Attention.**[[PDF](https://arxiv.org/abs/1911.09333v1)]<br>
*Zewei Sun, Shujian Huang, Hao-Ran Wei, Xin-yu Dai, Jiajun Chen.*<br>

**Benign Examples: Imperceptible Changes Can Enhance Image Translation Performance.**[[PDF](http://iphome.hhi.de/samek/pdf/SriAAAI20.pdf)]<br>
*Vignesh Srinivasan, Klaus-Robert Müller, [Wojciech Samek](http://iphome.hhi.de/samek/), Shinichi Nakajima.*<br>

**Multimodal Structure-Consistent Image-to-Image Translation.**<br>
*Che-Tsung Lin, Yen-Yi Wu, Po-Hao Hsu, Shang-Hong Lai.*<br>

**GAN-Based Unpaired Chinese Character Image Translation via Skeleton Transformation and Stroke Rendering.**<br>
*Yiming Gao, Jiangqin Wu.*<br>

### ACM MM 2020

**Retrieval Guided Unsupervised Multi-domain Image-to-Image Translation.**[[PDF](https://arxiv.org/abs/2008.04991)] <br>
*Raul Gomez, Yahui Liu, Marco De Nadai, Dimosthenis Karatzas, Bruno Lepri, Nicu Sebe.*<br>

**Cross-Granularity Learning for Multi-Domain Image-to-Image Translation.**[[PDF](https://dl.acm.org/doi/abs/10.1145/3394171.3413656)]<br>
*Huiyuan Fu, Ting Yu, Xin Wang, Huadong Ma.*<br>

**Describe What to Change: A Text-guided Unsupervised Image-to-Image Translation Approach.**[[PDF](https://arxiv.org/abs/2008.04200)] <br>
*Yahui Liu, Marco De Nadai, Deng Cai, Huayang Li, Xavier Alameda-Pineda, Nicu Sebe, Bruno Lepri.*<br>

**DAGAN: Dual Attention GANs for Semantic Image Synthesis.**[[PDF](https://arxiv.org/abs/2008.13024)] [[Github](https://github.com/Ha0Tang/DAGAN)]<br>
*Hao Tang, Song Bai, Nicu Sebe.*<br>

**From Design Draft to Real Attire: Unaligned Fashion Image Translation.**[[PDF](https://arxiv.org/abs/2008.01023)] [[Project](https://victoriahy.github.io/MM2020/)]<br>
*Yu Han, Shuai Yang, Wenjing Wang, Jiaying Liu.*<br>

### Journal 2020

**Homomorphic Interpolation Network for Unpaired Image-to-image Translation.**<br>
*Ying-Cong Chen, Jiaya Jia.*<br>
TPAMI 2020. [[PDF](https://www.yingcong.me/publication/chen-2020-homomorphic/)]

**Learning to Caricature via Semantic Shape Transform.**<br>
*Wenqing Chu, Wei-Chih Hung, Yi-Hsuan Tsai, Yu-Ting Chang, Yijun Li, Deng Cai, Ming-Hsuan Yang.*<br>
IJCV 2020. [[PDF](https://arxiv.org/abs/2008.05090)]

**Unsupervised multi-modal Styled Content Generation.**<br>
*Omry Sendik, Dani Lischinski, Daniel Cohen-Or.*<br>
TOG 2020. [[PDF](https://arxiv.org/abs/2001.03640)] [[TOG 2020 Papers On The Web](https://kesen.realtimerendering.com/sig2020.html)]

**MichiGAN: Multi-Input-Conditioned Hair Image Generation for Portrait Editing.**<br>
*Zhentao Tan, [Menglei Chai](https://mlchai.com/), Dongdong Chen, Jing Liao, Qi Chu, Lu Yuan, Sergey Tulyakov, Nenghai Yu.*
TOG 2020. [[PDF](https://mlchai.com/files/tan2020michigan.pdf)]

**DCMIT: Unsupervised Multi-Domain Multimodal Image-to-Image Translation with Explicit Domain-Constrained Disentanglement.**</br>
*Weihao Xia, Yujiu Yang, Jing-Hao Xue.*</br>
Neural Networks 2020. [[PDF](https://arxiv.org/abs/1911.00622)]

**GANILLA: Generative Adversarial Networks for Image to Illustration Translation.**<br>
*Samet Hicsonmez, Nermin Samet, Emre Akbas, Pinar Duygulu.*<br>
Image and Vision Computing 2020. [[PDF](https://arxiv.org/abs/2002.05638)] [[Github](https://github.com/giddyyupp/ganilla)]

### Others 2020

**Online Exemplar Fine-Tuning for Image-to-Image Translation.**<br>
*Taewon Kang, Soohyun Kim, Sunwoo Kim, Seungryong Kim.*<br>                
arxiv 2020. [[PDF](https://arxiv.org/abs/2011.09330)]

**Liquid Warping GAN with Attention: A Unified Framework for Human Image Synthesis.**<br>
*Wen Liu, Zhixin Piao, Zhi Tu, Wenhan Luo, Lin Ma, Shenghua Gao.*<br>                
TPAMI 2021. [[PDF](https://arxiv.org/abs/2011.09055)] [[Github](https://github.com/iPERDance/iPERCore)]

**Unsupervised Image-to-Image Translation Via Pre-trained StyleGAN2 Network.**<br>
*Jialu Huang, Jing Liao, Sam Kwong.*<br>                
arxiv 2020. [[PDF](https://arxiv.org/abs/2010.05713)] [[Github](https://github.com/HideUnderBush/UI2I_via_StyleGAN2)]

**The Surprising Effectiveness of Linear Unsupervised Image-to-Image Translation.**<br>
*Eitan Richardson, Yair Weiss.*<br>                
arxiv 2020. [[PDF](https://arxiv.org/abs/2007.12568)] [[Github](https://github.com/eitanrich/lin-im2im)]

**MatchGAN: A Self-Supervised Semi-Supervised Conditional Generative Adversarial Network.**</br>
*Jiaze Sun, Binod Bhattarai, Tae-Kyun Kim.*</br>
ACCV 2020. [[PDF](https://arxiv.org/abs/2006.06614)] [[Github](https://github.com/justin941208/MatchGAN)]

**RF-GAN: A Light and Reconfigurable Network for Unpaired Image-to-Image Translation.**<br>
*Ali Koksal, Shijian Lu.*<br>
ACCV 2020. [[PDF](https://openaccess.thecvf.com/content/ACCV2020/papers/Koksal_RF-GAN_A_Light_and_Reconfigurable_Network_for_Unpaired_Image-to-Image_Translation_ACCV_2020_paper.pdf)]

**FairfaceGAN: Fairness-aware Facial Image-to-Image Translation.**<br>
*Sunhee Hwang, Sungho Park, Dohyung Kim, Mirae Do, Hyeran Byun.*<br>
BMVC 2020. [[PDF](https://arxiv.org/abs/2012.00282)]

**Network-to-Network Translation with Conditional Invertible Neural Networks.**<br>
*[Robin Rombach](https://github.com/rromb), [Patrick Esser](https://github.com/pesser), [Björn Ommer](https://hci.iwr.uni-heidelberg.de/Staff/bommer).*<br>
NeurIPS 2020. [[PDF](https://arxiv.org/abs/2005.13580)] [[Github](https://github.com/CompVis/net2net)] [[Project](https://compvis.github.io/net2net/)]

**Semantically Adaptive Image-to-image Translation for Domain Adaptation of Semantic Segmentation.**<br>
*Luigi Musto, Andrea Zinelli.*<br>
BMVC 2020. [[PDF](https://arxiv.org/abs/2009.01166)] 

**Future Urban Scenes Generation Through Vehicles Synthesis.**</br>
*Alessandro Simoni, Luca Bergamini, Andrea Palazzi, Simone Calderara, Rita Cucchiara.*</br>
ICPR 2020. [[PDF](https://arxiv.org/abs/2007.00323)] [[Github](https://github.com/alexj94/future_urban_scene_generation)]

**Augmented Cyclic Consistency Regularization for Unpaired Image-to-Image Translation.**<br>
*Takehiko Ohkawa, Naoto Inoue, Hirokatsu Kataoka, Nakamasa Inoue.*<br>
ICPR 2020. [[PDF](https://arxiv.org/abs/2003.00187)]

**Pixel-based Facial Expression Synthesis.**<br>
*Arbish Akram and Nazar Khan.*<br>
ICPR 2020. [[PDF](https://arxiv.org/pdf/2010.14397)]

**DeepI2I: Enabling Deep Hierarchical Image-to-Image Translation by Transferring from GANs.**<br>
*yaxing wang, Lu Yu, Joost van de Weijer.*<br>
NeurIPS 2020. [[PDF](https://arxiv.org/abs/2011.05867)] [[Github](https://github.com/yaxingwang/DeepI2I)]

**GAIT: Gradient Adjusted Unsupervised Image-to-Image Translation.**<br>
*Ibrahim Batuhan Akkaya, Ugur Halici.*<br>
ICIP 2020. [[PDF](https://arxiv.org/abs/2009.00878)]

**Identity-Preserving Realistic Talking Face Generation.**<br>
*Sanjana Sinha, Sandika Biswas, Brojeshwar Bhowmick.*<br>
IJCNN 2020. [[PDF](https://arxiv.org/abs/2005.12318)]

**Domain Bridge for Unpaired Image-to-Image Translation and Unsupervised Domain Adaptation.**<br>
*Fabio Pizzati, Raoul de Charette, Michela Zaccaria, Pietro Cerri.*<br>
WACV 2020. [[PDF](https://arxiv.org/abs/1910.10563v3)]

**U-GAT-IT: Unsupervised Generative Attentional Networks with Adaptive Layer-Instance Normalization for Image-to-Image Translation.**<br>
*Junho Kim, Minjae Kim, Hyeonwoo Kang, Kwanghee Lee.*<br>
[ICLR 2020](https://openreview.net/group?id=ICLR.cc/2020/Conference). [[PDF](https://arxiv.org/abs/1907.10830)] [[Official Tensorflow](https://github.com/taki0112/UGATIT)] [[Pytorch](https://github.com/znxlwm/UGATIT-pytorch)] [[photo2cartoon](https://github.com/minivision-ai/photo2cartoon)] [[Morph UGATIT](https://github.com/shoutOutYangJie/Morph-UGATIT)]

## 2019

### NeurIPS 2019 
[[accepted paper list](https://NeurIPS.cc/Conferences/2019/AcceptedPapersInitial)]

**Adversarial Self-Defense for Cycle-Consistent GANs.** [[PDF](https://arxiv.org/abs/1908.01517)] [[Project](http://ai.bu.edu/selfadv/)] [[Github](https://github.com/dbash/pix2pix_cyclegan_guess_noise/)]<br>
*Dina Bashkirova, Ben Usman, Kate Saenko.*

**Multi-mapping Image-to-Image Translation via Learning Disentanglement.** [[PDF](https://arxiv.org/abs/1909.07877)]<br>
*Xiaoming Yu, Yuanqi Chen, Shan Liu, Thomas Li, Ge Li.*

**Flow-based Image-to-Image Translation with Feature Disentanglement.** [[PDF](http://papers.NeurIPS.cc/paper/8670-flow-based-image-to-image-translation-with-feature-disentanglement.pdf)]<br>
*Ruho Kondo, Keisuke Kawano, Satoshi Koide, Takuro Kutsuna.*

**Explicitly Disentangling Image Content From Translation And Rotation With Spatial-VAE.** [[PDF](https://arxiv.org/abs/1909.11663)]<br>
Tristan Bepler, Ellen Zhong, Kotaro Kelley, Edward Brignole, Bonnie Berger.*

**Learning to Predict Layout-to-image Conditional Convolutions for Semantic Image Synthesis.** [[PDF](https://arxiv.org/abs/1910.06809)]<br>
*Xihui Liu, Guojun Yin, Jing Shao, Xiaogang Wang, Hongsheng Li.*

### ICCV 2019 
[[accepted paper list](http://openaccess.thecvf.com/ICCV2019.py)]

**PuppetGAN: Cross-domain Image Manipulation by Demonstration.** [[PDF](https://arxiv.org/abs/1901.10024)] [[Unofficial](https://github.com/GiorgosKarantonis/PuppetGAN)]<br>
*Ben Usman, Nick Dufour, Kate Saenko, Chris Bregler.*

**Tex2Shape: Detailed Full Human Body Geometry From a Single Image.** [[PDF](http://openaccess.thecvf.com/content_ICCV_2019/html/Alldieck_Tex2Shape_Detailed_Full_Human_Body_Geometry_From_a_Single_Image_ICCV_2019_paper.html)]<br>
*Thiemo Alldieck, Gerard Pons-Moll, Christian Theobalt, Marcus Magnor.*

**Face-to-Parameter Translation for Game Character Auto-Creation.** [[PDF](http://openaccess.thecvf.com/content_ICCV_2019/papers/Shi_Face-to-Parameter_Translation_for_Game_Character_Auto-Creation_ICCV_2019_paper.pdf)] <br>
*Tianyang Shi, Yi Yuan, Changjie Fan, Zhengxia Zou, Zhenwei Shi, Yong Liu.*

**Learning Fixed Points in Generative Adversarial Networks: From Image-to-Image Translation to Disease Detection and Localization.** [[PDF](http://openaccess.thecvf.com/content_ICCV_2019/papers/Siddiquee_Learning_Fixed_Points_in_Generative_Adversarial_Networks_From_Image-to-Image_Translation_ICCV_2019_paper.pdf)] <br>
*Md Mahfuzur Rahman Siddiquee, Zongwei Zhou, Nima Tajbakhsh, Ruibin Feng, Michael B. Gotway, Yoshua Bengio, Jianming Liang.*

**Interactive Sketch & Fill: Multiclass Sketch-to-Image Translation.** [[PDF](http://openaccess.thecvf.com/content_ICCV_2019/papers/Ghosh_Interactive_Sketch__Fill_Multiclass_Sketch-to-Image_Translation_ICCV_2019_paper.pdf)] <br>
*Arnab Ghosh, Richard Zhang, Puneet K. Dokania, Oliver Wang, Alexei A. Efros, Philip H. S. Torr, Eli Shechtman.*

**Deep CG2Real: Synthetic-to-Real Translation via Image Disentanglement.** [[PDF](http://openaccess.thecvf.com/content_ICCV_2019/papers/Bi_Deep_CG2Real_Synthetic-to-Real_Translation_via_Image_Disentanglement_ICCV_2019_paper.pdf)]<br>
*Sai Bi, Kalyan Sunkavalli, Federico Perazzi, Eli Shechtman, Vladimir G. Kim, Ravi Ramamoorthi.*

**Co-Evolutionary Compression for Unpaired Image Translation.** [[PDF](http://openaccess.thecvf.com/content_ICCV_2019/html/Shu_Co-Evolutionary_Compression_for_Unpaired_Image_Translation_ICCV_2019_paper.html)]<br>
*Han Shu, Yunhe Wang, Xu Jia, Kai Han, Hanting Chen, Chunjing Xu, Qi Tian, Chang Xu.*

**Sym-Parameterized Dynamic Inference for Mixed-Domain Image Translation.** [[PDF](http://openaccess.thecvf.com/content_ICCV_2019/html/Chang_Sym-Parameterized_Dynamic_Inference_for_Mixed-Domain_Image_Translation_ICCV_2019_paper.html)]<br>
*Simyung Chang, SeongUk Park, John Yang, Nojun Kwak.*

**RelGAN: Multi-Domain Image-to-Image Translation via Relative Attributes.** [[PDF](http://openaccess.thecvf.com/content_ICCV_2019/html/Wu_RelGAN_Multi-Domain_Image-to-Image_Translation_via_Relative_Attributes_ICCV_2019_paper.html)]<br>
*Po-Wei Wu, Yu-Jing Lin, Che-Han Chang, Edward Y. Chang, Shih-Wei Liao.*

**ADSPM: Attribute-Driven Spontaneous Motion in Unpaired Image Translation.**[[PDF](http://openaccess.thecvf.com/content_ICCV_2019/html/Wu_Attribute-Driven_Spontaneous_Motion_in_Unpaired_Image_Translation_ICCV_2019_paper.html)][[Github](https://github.com/mikirui/ADSPM)]<br>
*Ruizheng Wu, Xin Tao, Xiaodong Gu, Xiaoyong Shen, Jiaya Jia.*

**Everybody Dance Now.** [[PDF](http://openaccess.thecvf.com/content_ICCV_2019/html/Chan_Everybody_Dance_Now_ICCV_2019_paper.html)]<br>
*Caroline Chan, Shiry Ginosar, Tinghui Zhou, Alexei A. Efros.*

**Multimodal Style Transfer via Graph Cuts.** [[PDF](http://openaccess.thecvf.com/content_ICCV_2019/html/Zhang_Multimodal_Style_Transfer_via_Graph_Cuts_ICCV_2019_paper.html)]<br>
*Yulun Zhang, Chen Fang, Yilin Wang, Zhaowen Wang, Zhe Lin, Yun Fu, Jimei Yang.*

**A Closed-Form Solution to Universal Style Transfer.** [[PDF](http://openaccess.thecvf.com/content_ICCV_2019/html/Lu_A_Closed-Form_Solution_to_Universal_Style_Transfer_ICCV_2019_paper.html)]<br>
*Ming Lu, Hao Zhao, Anbang Yao, Yurong Chen, Feng Xu, Li Zhang.*

**Guided Image-to-Image Translation With Bi-Directional Feature Transformation.** [[PDF](http://openaccess.thecvf.com/content_ICCV_2019/html/AlBahar_Guided_Image-to-Image_Translation_With_Bi-Directional_Feature_Transformation_ICCV_2019_paper.html)]<br>
*Badour AlBahar, Jia-Bin Huang.*

**FUNIT: Few-Shot Unsupervised Image-to-Image Translation.** [[PDF](http://openaccess.thecvf.com/content_ICCV_2019/html/Liu_Few-Shot_Unsupervised_Image-to-Image_Translation_ICCV_2019_paper.html)]<br>
*Ming-Yu Liu, Xun Huang, Arun Mallya, Tero Karras, Timo Aila, Jaakko Lehtinen, Jan Kautz.*

**InGAN: Capturing and Retargeting the "DNA" of a Natural Image.** [[PDF](http://openaccess.thecvf.com/content_ICCV_2019/html/Shocher_InGAN_Capturing_and_Retargeting_the_DNA_of_a_Natural_Image_ICCV_2019_paper.html)]<br>
*Assaf Shocher, Shai Bagon, Phillip Isola, Michal Irani.*

**Liquid Warping GAN: A Unified Framework for Human Motion Imitation, Appearance Transfer and Novel View Synthesis.** [[PDF](http://openaccess.thecvf.com/content_ICCV_2019/html/Liu_Liquid_Warping_GAN_A_Unified_Framework_for_Human_Motion_Imitation_ICCV_2019_paper.html)]<br>
*Wen Liu, Zhixin Piao, Jie Min, Wenhan Luo, Lin Ma, Shenghua Gao.*

### CVPR 2019 
[[accepted paper list](https://openaccess.thecvf.com/CVPR2019)]

**Multi-Channel Attention Selection GANs for Guided Image-to-Image Translation.**[[PDF](https://arxiv.org/abs/2002.01048)] [[Githtub](https://github.com/Ha0Tang/SelectionGAN)]<br>
*Hao Tang, Philip H. S. Torr, Nicu Sebe.*<br>                

**CollaGAN : Collaborative GAN for Missing Image Data Imputation.**[[PDF](https://arxiv.org/abs/1901.09764)]<br>
*Dongwook Lee, Junyoung Kim, Won-Jin Moon, Jong Chul Ye.*<br>

**Reversible GANs for Memory-efficient Image-to-Image Translation.**[[PDF](https://arxiv.org/abs/1902.02729)] [[Project](https://tychovdo.github.io/RevGAN/)] [[Github](https://github.com/tychovdo/RevGAN)]<br> 
*[Tycho F.A. van der Ouderaa](https://tychovdo.github.io/), [Daniel E. Worrall](https://deworrall92.github.io/).*<br>

**Latent Filter Scaling for Multimodal Unsupervised Image-To-Image Translation.** [[PDF](http://openaccess.thecvf.com/content_CVPR_2019/html/Alharbi_Latent_Filter_Scaling_for_Multimodal_Unsupervised_Image-To-Image_Translation_CVPR_2019_paper.html)]<br>
*Yazeed Alharbi, Neil Smith, Peter Wonka.*<br>

**Attention-Aware Multi-Stroke Style Transfer.** [[PDF](http://openaccess.thecvf.com/content_CVPR_2019/html/Yao_Attention-Aware_Multi-Stroke_Style_Transfer_CVPR_2019_paper.html)]<br>
*Yuan Yao, Jianqiang Ren, Xuansong Xie, Weidong Liu, Yong-Jin Liu, Jun Wang.*<br>

**Textured Neural Avatars.** [[PDF](http://openaccess.thecvf.com/content_CVPR_2019/html/Shysheya_Textured_Neural_Avatars_CVPR_2019_paper.html)]<br>
*Aliaksandra Shysheya, Egor Zakharov, Kara-Ali Aliev, Renat Bashirov, Egor Burkov, Karim Iskakov, Aleksei Ivakhnenko, Yury Malkov, Igor Pasechnik, Dmitry Ulyanov, Alexander Vakhitov, Victor Lempitsky.*<br>

**Homomorphic Latent Space Interpolation for Unpaired Image-To-Image Translation.** [[PDF](http://openaccess.thecvf.com/content_CVPR_2019/html/Chen_Homomorphic_Latent_Space_Interpolation_for_Unpaired_Image-To-Image_Translation_CVPR_2019_paper.html)] [[Github](https://github.com/yingcong/HomoInterpGAN)]<br>
*[Ying-Cong Chen](https://yingcong.github.io/), Xiaogang Xu, Zhuotao Tian, Jiaya Jia.*<br>

**Multi-Channel Attention Selection GAN With Cascaded Semantic Guidance for Cross-View Image Translation.** [[PDF](http://openaccess.thecvf.com/content_CVPR_2019/papers/Tang_Multi-Channel_Attention_Selection_GAN_With_Cascaded_Semantic_Guidance_for_Cross-View_CVPR_2019_paper.pdf)]<br>
*Hao Tang, Dan Xu, Nicu Sebe, Yanzhi Wang, Jason J. Corso, Yan Yan.*<br>

**TraVeLGAN: Image-To-Image Translation by Transformation Vector Learning.** [[PDF](http://openaccess.thecvf.com/content_CVPR_2019/html/Amodio_TraVeLGAN_Image-To-Image_Translation_by_Transformation_Vector_Learning_CVPR_2019_paper.html)]<br>
*Matthew Amodio, Smita Krishnaswamy.*<br>

**ReversibleGANs for Memory-Efficient ImageTo Image Translation.** [[PDF](http://openaccess.thecvf.com/content_CVPR_2019/html/van_der_Ouderaa_Reversible_GANs_for_Memory-Efficient_Image-To-Image_Translation_CVPR_2019_paper.html)]<br>
*Tycho F.A. van der Ouderaa, Daniel E. Worrall.*<br>

**Image-To-Image Translation via Group-Wise Deep Whitening-And-Coloring Transformation.** [[PDF](http://openaccess.thecvf.com/content_CVPR_2019/html/Cho_Image-To-Image_Translation_via_Group-Wise_Deep_Whitening-And-Coloring_Transformation_CVPR_2019_paper.html)] [[Github](https://github.com/WonwoongCho/GDWCT)]<br>
*Wonwoong Cho, Sungha Choi, David Keetae Park, Inkyu Shin, Jaegul Choo.*<br>

**Towards Visual Feature Translation.** [[PDF](http://openaccess.thecvf.com/content_CVPR_2019/html/Hu_Towards_Visual_Feature_Translation_CVPR_2019_paper.html)]<br>
*Jie Hu, Rongrong Ji, Hong Liu, Shengchuan Zhang, Cheng Deng, Qi Tian.*<br>

**Towards Instance-Level Image-To-Image Translation.** [[PDF](http://openaccess.thecvf.com/content_CVPR_2019/html/Hu_Towards_Visual_Feature_Translation_CVPR_2019_paper.html)]<br>
*Zhiqiang Shen, Mingyang Huang, Jianping Shi, Xiangyang Xue, Thomas S. Huang.*<br>

**Art2Real: Unfolding the Reality of_Artworks via Semantically-Aware Image-To-Image Translation.** [[PDF](http://openaccess.thecvf.com/content_CVPR_2019/html/Tomei_Art2Real_Unfolding_the_Reality_of_Artworks_via_Semantically-Aware_Image-To-Image_Translation_CVPR_2019_paper.html)]<br>
*Matteo Tomei, Marcella Cornia, Lorenzo Baraldi, Rita Cucchiara.*<br>

**TransGaGa：Geometry-Aware Unsupervised Image To Image Translation.** [[PDF](http://openaccess.thecvf.com/content_CVPR_2019/html/Wu_TransGaGa_Geometry-Aware_Unsupervised_Image-To-Image_Translation_CVPR_2019_paper.html)] [[arxiv](https://arxiv.org/abs/1904.09571)] [[project](https://wywu.github.io/projects/TGaGa/TGaGa.html)]<br>
*Wayne Wu, Kaidi Cao, Cheng Li, Chen Qian, Chen Change Loy.*<br>

### ICLR 2019 
[[accepted paper list](https://openreview.net/group?id=ICLR.cc/2019/Conference)]

**Diversity-Sensitive Conditional Generative Adversarial Networks.**[[PDF](https://arxiv.org/abs/1901.09024)]<br> 
*Dingdong Yang, Seunghoon Hong, Yunseok Jang, Tianchen Zhao, Honglak Lee.*<br>

**InstaGAN: Instance-aware Image-to-Image Translation.** [[PDF](https://openreview.net/forum?id=ryxwJhC9YX)] [[Github](https://github.com/sangwoomo/instagan)]<br>
*Sangwoo Mo, Minsu Cho, Jinwoo Shin.*<br>

**Harmonic Unpaired Image-to-image Translation.** [[PDF](https://openreview.net/forum?id=S1M6Z2Cctm)] <br>
*Rui Zhang, Tomas Pfister, Jia Li.*<br>

**Local Image-to-Image Translation via Pixel-wise Highway Adaptive Instance Normalization.** [[PDF](https://openreview.net/forum?id=HJgTHnActQ)] <br>
*Wonwoong Cho, Seunghwan Choi, Junwoo Park, David Keetae Park, Tao Qin, Jaegul Choo.*

**EG-UNIT: Exemplar Guided Unsupervised Image-to-Image Translation with Semantic Consistency.** [[PDF](https://openreview.net/forum?id=S1lTg3RqYQ)]<br>
*Liqian Ma, Xu Jia, Stamatios Georgoulis, Tinne Tuytelaars, Luc Van Gool.*<br>

**Unsupervised one-to-many image translation.** [[PDF](https://openreview.net/forum?id=B1GIQhCcYm)]<br>
*Samuel Lavoie-Marchildon, Sebastien Lachapelle, Mikołaj Bińkowski, Aaron Courville, Yoshua Bengio, R Devon Hjelm.*<br>

**Unsupervised Image to Sequence Translation with Canvas-Drawer Networks.** [[PDF](https://openreview.net/forum?id=ByeLBj0qFQ)]<br>
*Kevin Frans, Chin-Yi Cheng.*<br>

**Unsupervised Video-to-Video Translation.** [[PDF](https://openreview.net/forum?id=SkgKzh0cY7)]<br>
*Dina Bashkirova, Ben Usman, Kate Saenko.*<br>

### Journal 2019

**VR Facial Animation via Multiview Image Translation.**<br>
*Shih-En Wei, Jason Saragih, Tomas Simon, Adam W. Harley, Stephen Lombardi, Michal Perdoch, Alexander Hypes, Dawei Wang, Hernan Badino, Yaser Sheikh.*<br>
TOG 2019. [[PDF](https://research.fb.com/publications/vr-facial-animation-via-multiview-image-translation/)]

**Stylizing Video by Example.**<br> 
*Ondřej Jamriška, Šárka Sochorová, Ondřej Texler, Michal Lukáč, Jakub Fišer, Jingwan Lu, Eli Shechtman, Daniel Sýkora.*<br>
TOG 2019. [[PDF](https://dcgi.fel.cvut.cz/home/sykorad/Jamriska19-SIG.pdf)]

**VR Facial Animation via Multiview Image Translation.**<br>
*Shih-En Wei, Jason Saragih, Tomas Simon, Adam W. Harley, Stephen Lombardi, Michal Perdoch, Alexander Hypes, Dawei Wang, Hernan Badino, Yaser Sheikh.*<br>
TOG 2019. [[PDF](https://research.fb.com/publications/vr-facial-animation-via-multiview-image-translation/)]

**DosGAN: Exploring Explicit Domain Supervision for Latent Space Disentanglement in Unpaired Image-to-Image Translation.**<br>
*[Jianxin Lin](http://home.ustc.edu.cn/~linjx/), [Zhibo Chen](http://staff.ustc.edu.cn/~chenzhibo/), Yingce Xia, Sen Liu, Tao Qin, Jiebo Luo.*<br>
TPAMI 2019. [[PDF](https://arxiv.org/abs/1902.03782)] [[Github](https://github.com/linjx-ustc1106/DosGAN-PyTorch)]

**DRIT++: Diverse Image-to-Image Translation via Disentangled Representations.**<br>
*Hsin-Ying Lee, Hung-Yu Tseng, Qi Mao, Jia-Bin Huang, Yu-Ding Lu, Maneesh Singh, Ming-Hsuan Yang.*<br>
IJCV 2019. [[PDF](https://arxiv.org/abs/1905.01270)] [[Project](http://vllab.ucmerced.edu/hylee/DRIT_pp/)] [[Github](https://github.com/HsinYingLee/MDMM)]

**Masked Linear Regression for Learning Local Receptive Fields for Facial Expression Synthesis.**<br>
*Nazar Khan, Arbish Akram, Arif Mahmood, Sania Ashraf, Kashif Murtaza.*<br>
IJCV 2019. [[PDF](http://faculty.pucit.edu.pk/nazarkhan/work/expression_mapping/mr_ijcv_manuscript.pdf)] [[Github](https://github.com/arbishakram/masked_regression_code)]

**Show, Attend and Translate: Unsupervised Image Translation with Self-Regularization and Attention.**<br>
*Chao Yang, Taehwan Kim, Ruizhe Wang, Hao Peng, C.-C. Jay Kuo.*<br>
TIP 2019. [[PDF](https://arxiv.org/abs/1806.06195)]

**AttGAN: Facial Attribute Editing by Only Changing What You Want.**<br> 
*Zhenliang He, Wangmeng Zuo, Meina Kan, Shiguang Shan, Xilin Chen.*<br>
TIP 2019. [[PDF](https://arxiv.org/abs/1711.10678)] [[Github](https://github.com/LynnHo/AttGAN-Tensorflow)]

**Asymmetric GAN for Unpaired Image-to-Image Translation.**<br>
*Hao Tang, Dan Xu, Hong Liu, Nicu Sebe.*<br>
TIP 2019 (ACCV 2018 Extension) [[PDF](https://arxiv.org/abs/1912.06931)] [[GitHub](https://github.com/Ha0Tang/AsymmetricGAN)]

### Others 2019

**SMIT: Stochastic Multi-Label Image-to-Image Translation.**<br>
*Andrés Romero, Pablo Arbeláez, Luc Van Gool, Radu Timofte.*<br>
ICCV 2019 Workshops. [[PDF](https://arxiv.org/abs/1812.03704)] [[Github](https://github.com/BCV-Uniandes/SMIT)]

**Exploiting Time-Series Image-to-Image Translation to Expand the Range of Wildlife Habitat Analysis.**<br>
*Ruobing Zheng, Ze Luo, Baoping Yan.*<br>
AAAI 2019. [[PDF](https://www.aaai.org/ojs/index.php/AAAI/article/view/3862)]

**Controllable Image-to-Video Translation: A Case Study on Facial Expression Generation.**<br>
*Lijie Fan, Wenbing Huang, Chuang Gan, Junzhou Huang, Boqing Gong.*<br>
AAAI 2019. [[PDF](https://arxiv.org/abs/1808.02992)]

**OT-CycleGAN: Guiding the One-to-one Mapping in CycleGAN via Optimal Transport.**<br>
*Guansong Lu, Zhiming Zhou, Yuxuan Song, Kan Ren, Yong Yu.*<br> 
AAAI 2019. [[PDF](https://arxiv.org/abs/1811.06284)] 

**C2-GAN: Cycle In Cycle Generative Adversarial Networks for Keypoint-Guided Image Generation.**<br>
*[Hao Tang](http://disi.unitn.it/~hao.tang/), [Dan Xu](http://www.robots.ox.ac.uk/~danxu/), [Gaowen Liu](https://dblp.uni-trier.de/pers/hd/l/Liu:Gaowen), [Wei Wang](https://weiwangtrento.github.io/), [Nicu Sebe](https://scholar.google.com/citations?user=stFCYOAAAAAJ&hl=en), [Yan Yan](https://scholar.google.com/citations?user=zhi-j1wAAAAJ&hl=en).*<br>
ACM MM 2019. [[PDF](https://arxiv.org/abs/1908.00999)] [[Project](http://disi.unitn.it/~hao.tang/project/C2GAN.html)] [[Github](https://github.com/Ha0Tang/C2GAN)]

**Towards Automatic Face-to-Face Translation.**<br>
*Prajwal Renukanand, Rudrabha Mukhopadhyay, Jerin Philip, Abhishek Jha, Vinay Namboodiri and C.V. Jawahar.*<br>
ACM MM 2019. [[PDF](https://dl.acm.org/doi/10.1145/3343031.3351066)] [[Github](https://github.com/Rudrabha/LipGAN)] [[Project](http://cvit.iiit.ac.in/research/projects/cvit-projects/facetoface-translation)]

**Preserving Semantic and Temporal Consistency for Unpaired Video-to-Video Translation.**<br>
*Kwanyong Park, Sanghyun Woo, Dahun Kim, Donghyeon Cho, In So Kweon.*<br>
ACM MM 2019. [[PDF](https://arxiv.org/abs/1908.07683)]

**Mocycle-GAN: Unpaired Video-to-Video Translation.**<br> 
*Yang Chen, Yingwei Pan, Ting Yao, Xinmei Tian, Tao Mei.*<br> 
ACM MM 2019. [[PDF](https://arxiv.org/abs/1908.09514)]

**Deliberation Learning for Image-to-Image Translation.**<br>
*Tianyu He, Yingce Xia, Jianxin Lin, Xu Tan, Di He, Tao Qin, Zhibo Chen.*<br>
IJCAI 2019. [[PDF](https://www.ijcai.org/Proceedings/2019/0345.pdf)]

**Image-to-Image Translation with Multi-Path Consistency Regularization.**<br>
*Jianxin Lin, Yingce Xia, Yijun Wang, Tao Qin, Zhibo Chen.*<br>
IJCAI 2019. [[PDF](https://arxiv.org/abs/1905.12498)]

**RL-GAN: Transfer Learning for Related Reinforcement Learning Tasks via Image-to-Image Translation.**<br>
*Shani Gamrian, Yoav Goldberg.*<br>
ICML 2019. [[accepted paper list](http://proceedings.mlr.press/v97/)] [[PDF](https://arxiv.org/abs/1806.07377)] [[Supplementary PDF](http://proceedings.mlr.press/v97/fujimoto19a/fujimoto19a-supp.pdf)] [[Github](https://github.com/ShaniGam/RL-GAN)]

**CartoonRenderer: An Instance-based Multi-Style Cartoon Image Translator.**<br>
*Yugang Chen, Muchun Chen, Chaoyue Song, Bingbing Ni.*<br>
International Conference on Multimedia Modeling (MMM2020). [[PDF](https://arxiv.org/abs/1911.06102)] 

**AttentionGAN: Attention-Guided Generative Adversarial Networks for Unsupervised Image-to-Image Translation.**<br>
*Hao Tang, Dan Xu, Nicu Sebe, Yan Yan.*<br>
IJCNN 2019. [[Github](https://github.com/Ha0Tang/AttentionGAN)]

**CrossNet: Latent Cross-Consistency for Unpaired Image Translation.**<br>
*Omry Sendik, Dani Lischinski, [Daniel Cohen-Or](https://danielcohenor.com/).*<br>
WACV 2020. [[PDF](https://arxiv.org/abs/1901.04530)]

**DeepHist: Differentiable Joint and Color Histogram Layers for Image-to-Image Translation.**<br>
*Mor Avi-Aharon, Assaf Arbelle, Tammy Riklin Raviv.*<br>
arxiv 2019. [[PDF](https://arxiv.org/abs/2005.03995)] [[GIthub](https://github.com/winfried-loetzsch/deep-hist)]

**Cross-Domain Cascaded Deep Feature Translation.**<br>
*Oren Katzir, Dani Lischinski, Daniel Cohen-Or.*<br>
arxiv 2019. [[PDF](https://arxiv.org/abs/1906.01526)]

**Implicit Pairs for Boosting Unpaired Image-to-Image Translation.**<br>
*Yiftach Ginger, Dov Danon, Hadar Averbuch-Elor, Daniel Cohen-Or.*<br>
arxiv 2019. [[PDF](https://arxiv.org/abs/1904.06913)]

**Unpaired Image Translation via Adaptive Convolution-based Normalization.**<br>
*Wonwoong Cho, Kangyeol Kim, Eungyeup Kim, Hyunwoo J. Kim, Jaegul Choo.*<br>
arxiv 2019. [[PDF]( https://arxiv.org/abs/1911.13271)]

**EDIT: Exemplar-Domain Aware Image-to-Image Translation.**<br>
*Yuanbin Fu, Jiayi Ma, Lin Ma, Xiaojie Guo.*<br>
arxiv 2019. [[PDF](https://arxiv.org/abs/1911.10520)] [[GitHub](http://t.cn/AigvDwW3)]

**injectionGAN: Toward Learning a Unified Many-to-Many Mapping for Diverse Image Translation.**<br>
*Wenju Xu, Shawn Keshmiri, Guanghui Wang.*<br>
arxiv 2019. [[PDF](https://arxiv.org/abs/1905.08766)]

## Before 2018

**Image to Image Translation for Domain Adaptation..**<br>
*Zak Murez, Soheil Kolouri, David Kriegman, [Ravi Ramamoorthi](https://cseweb.ucsd.edu/~ravir), Kyungnam Kim..*<br>
CVPR 2018. [[PDF](http://openaccess.thecvf.com/content_cvpr_2018/papers/Murez_Image_to_Image_CVPR_2018_paper.pdf)]

**StarGAN: Unified Generative Adversarial Networks for Multi-Domain Image-to-Image Translation.**<br>
*Yunjey Choi, Minje Choi, Munyoung Kim, Jung-Woo Ha, Sunghun Kim, Jaegul Choo.*<br>
CVPR 2018. [[Github](https://github.com/yunjey/StarGAN)] [[PDF](https://arxiv.org/abs/1711.09020)]

**UNIT: Unsupervised Image-to-Image Translation Networks.**<br>
*Ming-Yu Liu, Thomas Breuel, Jan Kautz.*<br>
NeurIPS 2017. [[PDF](https://arxiv.org/abs/1703.00848)] [[Github](https://github.com/mingyuliutw/UNIT)]

**Fader Networks: Manipulating Images by Sliding Attributes.**<br>
*Guillaume Lample, Neil Zeghidour, Nicolas Usunier, Antoine Bordes, Ludovic Denoyer, Marc'Aurelio Ranzato.*<br>
NeurIPS 2017.  [[Github](https://github.com/facebookresearch/FaderNetworks)] [[PDF](https://arxiv.org/abs/1706.00409)]

**DTN: Unsupervised Cross-Domain Image Generation.**<br>
*Yaniv Taigman, Adam Polyak, Lior Wolf.*<br>
ICLR 2017. [[PDF](https://arxiv.org/abs/1611.02200)] [[Github](https://github.com/yunjey/domain-transfer-network)] 

**GeneGAN: Learning Object Transfiguration and Attribute Subspace from Unpaired Data.**<br>
*Shuchang Zhou, Taihong Xiao, Yi Yang, Dieqiao Feng, Qinyao He, Weiran He.*<br>
BMVC 2017. [[Github](https://github.com/Prinsphield/GeneGAN)] [[PDF](https://arxiv.org/abs/1705.04932)]

**Face-Age-cGAN: Face Aging With Conditional Generative Adversarial Networks.**<br>
*Grigory Antipov, Moez Baccouche, Jean-Luc Dugelay.*<br>
ICIP 2017. [[PDF](https://arxiv.org/abs/1702.01983)]

**DiscoGAN: Learning to Discover Cross-Domain Relations with Generative Adversarial Networks.**<br>
*Taeksoo Kim, Moonsu Cha, Hyunsoo Kim, Jung Kwon Lee, Jiwon Kim.*<br>
ICML 2017. [[Github](https://github.com/carpedm20/DiscoGAN-pytorch)] [[PDF](https://arxiv.org/abs/1703.05192)]

**DualGAN: Unsupervised Dual Learning for Image-to-Image Translation.**<br>
*Zili Yi, Hao Zhang, Ping Tan, Minglun Gong.*<br>
ICCV 2017. [[Github](https://github.com/duxingren14/DualGAN)] [[PDF](https://arxiv.org/abs/1704.02510)]

**CycleGAN: Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks.**<br>
*Jun-Yan Zhu, Taesung Park, Phillip Isola, Alexei A. Efros.*<br>
ICCV 2017. [[Project](https://junyanz.github.io/CycleGAN/)] [[Github](https://github.com/junyanz/CycleGAN)] [[pytorch-CycleGAN-and-pix2pix](https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix)] [[PDF](https://arxiv.org/pdf/1703.10593.pdf)]

**BicycleGAN: Toward Multimodal Image-to-Image Translation.**<br>
*Jun-Yan Zhu, Richard Zhang, Deepak Pathak, Trevor Darrell, Alexei A. Efros, Oliver Wang, Eli Shechtman.*<br>
NeurIPS 2017. [[PDF](https://arxiv.org/abs/1711.11586)] [[Project](https://junyanz.github.io/BicycleGAN/)] [[Github](https://github.com/junyanz/BicycleGAN)] [[TensorFlow](https://github.com/gitlimlab/BicycleGAN-Tensorflow)]

**pix2pix: Image-to-Image Translation with Conditional Adversarial Networks.**<br>
*Phillip Isola, Jun-Yan Zhu, Tinghui Zhou, Alexei A. Efros.*<br>
CVPR 2017. [[Project](https://phillipi.github.io/pix2pix/)] [[Github](https://github.com/phillipi/pix2pix)] [[PDF](https://arxiv.org/pdf/1611.07004.pdf)]

**IcGAN: Invertible Conditional GANs for Image Editing.**<br>
*Guim Perarnau, Joost van de Weijer, Bogdan Raducanu, Jose M. Álvarez.*<br>
NeurIPS 2016 Workshop on Adversarial Training. [[Github](https://github.com/Guim3/IcGAN)] [[PDF](https://arxiv.org/abs/1611.06355)]
