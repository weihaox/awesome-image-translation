
# Msic

## Free-Hand Sketch

**Deep Plastic Surgery: Robust and Controllable Image Editing with Human-Drawn Sketches.**<br>
*Shuai Yang, Zhangyang Wang, Jiaying Liu, Zongming Guo.*<br>
arxiv, 9 Jan 2020.
[[PDF](https://arxiv.org/abs/2001.02890)]

**Deep Learning for Free-Hand Sketch: A Survey.**<br>
*Peng Xu.*<br>
arxiv, 8 Jan 2020. [[PDF](https://arxiv.org/abs/2001.02600)]


**Interactive Sketch & Fill: Multiclass Sketch-to-Image Translation.**<br>
*[Arnab Ghosh](https://arnabgho.github.io/), [Richard Zhang](https://richzhang.github.io/), [Puneet K. Dokania](https://puneetkdokania.github.io/), [Oliver Wang](http://www.oliverwang.info/), [Alexei A. Efros](https://people.eecs.berkeley.edu/~efros/), [Philip H.S. Torr](http://www.robots.ox.ac.uk/~tvg/index.php), [Eli Shechtman](https://research.adobe.com/person/eli-shechtman/).*<br>
ICCV 2019. [[PDF](https://arxiv.org/abs/1909.11081v2)] [[Github](https://arnabgho.github.io/iSketchNFill/)]

**Examining Performance of Sketch-to-Image Translation Models with Multiclass Automatically Generated Paired Training Data.**<br>
*Dichao Hu.*<br>
arxiv, 2018. [[PDF](https://arxiv.org/abs/1811.00249)]

**Multi-Graph Transformer for Free-Hand Sketch Recognition.**<br>
*[Peng Xu](http://www.pengxu.net/), [Chaitanya K. Joshi](https://chaitjo.github.io/), [Xavier Bresson](https://www.ntu.edu.sg/home/xbresson/).*<br>
arxiv, 2019. [[PDF](https://arxiv.org/abs/1912.11258)] [[Github](https://github.com/PengBoXiangShang/multigraph_transformer)]

## Deep Learning on Embedded Systems

**FastDepth: Fast Monocular Depth Estimation on Embedded Systems.**<br>
*Diana Wofk, Fangchang Ma, Tien-Ju Yang, Sertac Karaman, Vivienne Sze.*<br>
ICRA, 2019.
[[Project](fastdepth.mit.edu)]
[[PDF](http://fastdepth.mit.edu/2019_icra_fastdepth.pdf)]
[[Github](https://github.com/dwofk/fast-depth)]

**NetAdapt: Platform-Aware Neural Network Adaptation for Mobile Applications.** <br>
*Tien-Ju Yang, Andrew Howard, Bo Chen, Xiao Zhang, Alec Go, Mark Sandler, Vivienne Sze, Hartwig Adam.*<br>
ECCV, 2018.
[[CVF](http://openaccess.thecvf.com/content_ECCV_2018/papers/Tien-Ju_Yang_NetAdapt_Platform-Aware_Neural_ECCV_2018_paper.pdf)]
[[PDF](https://arxiv.org/abs/1804.03230)]
[[Github](github.com/denru01/netadapt)]
[[Project](https://web.mit.edu/netadapt/)]

## Temporal- and Scale-Consistent Depth Estimation

**Exploiting Temporal Consistency for Real-time Video Depth Estimation.**<br>
*Haokui Zhang, Chunhua Shen, Ying Li, Yuanzhouhan Cao, Yu Liu, Youliang Yan.*<br>
ICCV, 2019. [[PDF](https://arxiv.org/abs/1908.03706.pdf)] [[Project](https://tinyurl.com/STCLSTM)]

**Unsupervised Scale-consistent Depth and Ego-motion Learning from Monocular Video.**<br>
*Jia-Wang Bian, Zhichao Li, Naiyan Wang, Huangying Zhan, Chunhua Shen, Ming-Ming Cheng, Ian Reid.* <br>
NeurIPS, 2019.  
[[PDF](https://papers.nips.cc/paper/8299-unsupervised-scale-consistent-depth-and-ego-motion-learning-from-monocular-video.pdf)] 
[[Github](https://github.com/JiawangBian/SC-SfMLearner-Release)]
[[Project](https://jwbian.net/sc-sfmlearner)]

## Reciprocal Computer Vision Tasks

**DSNet: Joint Learning for Scene Segmentation and Disparity Estimation** <br>
*Wujing Zhan, Xinqi Ou, Yunyi Yang and Long Chen* <br>
ICRA 2019. [[PDF](https://ieeexplore.ieee.org/document/8793573)] 

**Real-Time Joint Semantic Segmentation and Depth Estimation Using Asymmetric Annotations** <br> 
*Vladimir Nekrasov, Thanuja Dharmasiri, Andrew Spek, Tom Drummond, Chunhua Shen, Ian Reid.*<br> 
ICRA 2019. [[PDF](https://ieeexplore.ieee.org/document/8794220)]

**RDSNet: A New Deep Architecture for Reciprocal Object Detection and Instance Segmentation.** <br>
*Shaoru Wang, Yongchao Gong, Junliang Xing, Lichao Huang, Chang Huang, Weiming Hu.* <br>
AAAI 2020. [[PDF](https://arxiv.org/abs/1912.05070)] [[Github](https://github.com/wangsr126/RDSNet)]

**MOTSFusion: Track to Reconstruct and Reconstruct to Track.** <br>
*Jonathon Luiten, Tobias Fischer, Bastian Leibe.*<br>
[[PDF](https://arxiv.org/abs/1910.00130v1)] [[Github](https://github.com/tobiasfshr/MOTSFusion)]

**SR-Net: Cooperative Image Segmentation and Restoration in Adverse Environmental Conditions.** <br>
*Weihao Xia, Zhanglin Cheng, Yujiu Yang.*<br>
[[PDF](https://arxiv.org/abs/1911.00679)]

## When Deep Learning met Physics-Based Simulation

**Differentiable Programming for Physical Simulation.**<br>
*Yuanming Hu, Luke Anderson, Tzu-Mao Li, Qi Sun, Nathan Carr, Jonathan Ragan-Kelley, and Frédo Durand.*<br>
ICLR 2020.  [[PDF](https://arxiv.org/abs/1910.00935)] [[Github](https://github.com/yuanming-hu/taichi)]

**GarNet: A Two-Stream Network for Fast and Accurate 3D Cloth Draping.**<br>
*[Erhan Gundogdu](https://egundogdu.github.io/), Victor Constantin, Amrollah Seifoddini, Minh Dang, Mathieu Salzmann, Pascal Fua.*<br>
ICCV 2019. [[PDF](https://arxiv.org/abs/1811.10983)] [[Supplementary Material](https://www.epfl.ch/labs/cvlab/wp-content/uploads/2019/04/GarNet_supplementary.pdf)] [[Project](https://cvlab.epfl.ch/research/garment-simulation/garnet/)] [[Dataset](https://drive.switch.ch/index.php/s/7mAk9SoZ7J4uokt)]

## 3D Clothing Draping & 3D People Dressing

**GarNet: A Two-Stream Network for Fast and Accurate 3D Cloth Draping.**<br>
*[Erhan Gundogdu](https://egundogdu.github.io/), Victor Constantin, Amrollah Seifoddini, Minh Dang, Mathieu Salzmann, Pascal Fua.*<br>
ICCV 2019. [[PDF](https://arxiv.org/abs/1811.10983)] [[Supplementary Material](https://www.epfl.ch/labs/cvlab/wp-content/uploads/2019/04/GarNet_supplementary.pdf)] [[Project](https://cvlab.epfl.ch/research/garment-simulation/garnet/)] [[Dataset](https://drive.switch.ch/index.php/s/7mAk9SoZ7J4uokt)]

**Multi-Garment Net: Learning to Dress 3D People from Images.**<br>
*Bharat Lal Bhatnagar, Garvita Tiwari, Christian Theobalt, [Gerard Pons-Moll](https://www.mpi-inf.mpg.de/departments/computer-vision-and-machine-learning/people/gerard-pons-moll/)(REAL VIRTUAL HUMANS, MPII).*<br>
ICCV 2019. [[PDF](https://arxiv.org/abs/1908.06903)]

**Learning to Dress 3D People in Generative Clothing.**<br>
*CAPE: Clothed Auto Person Encoding.*<br>
*Dressing 3D Human Using Conditional Mesh-VAE-GAN.*<br>
*[Qianli Ma](https://ps.is.tue.mpg.de/person/qma), Jinlong Yang, Anurag Ranjan, Sergi Pujades, Gerard Pons-Moll, Siyu Tang, [Michael J. Black](https://ps.is.tuebingen.mpg.de/person/black).*<br>
[[PDF](https://arxiv.org/abs/1907.13615v2)]

**DRAPE: DRessing Any PErson.**<br>
*Peng Guan, Loretta Reiss, David A. Hirshberg, Alexander Weiss, Michael J. Black.*<br>
ACM Transactions on Graphics (TOG) 2012.
[[PDF](https://dl.acm.org/citation.cfm?doid=2185520.2185531)]
[[Project](https://ps.is.tue.mpg.de/research_projects/drape-dressing-any-person)]

**CLOTH3D: Clothed 3D Humans.**<br>
*Hugo Bertiche, Meysam Madadi, Sergio Escalera.*<br>
arxiv, 5 Dec 2019. [[PDF](https://arxiv.org/abs/1912.02792v1)]

## Restoration with Unpair or Misaligned Data

**EnlightenGAN: Deep Light Enhancement without Paired Supervision.**<br>
*Yifan Jiang, Xinyu Gong, Ding Liu, Yu Cheng, Chen Fang, Xiaohui Shen, Jianchao Yang, Pan Zhou, Zhangyang Wang.*<br>
[[PDF](https://arxiv.org/abs/1906.06972)] [[Github](https://github.com/TAMU-VITA/EnlightenGAN)] [[Dataset](https://github.com/TAMU-VITA/EnlightenGAN/issues/28)] [[KinD](https://arxiv.org/abs/1905.04161)]

**Unpaired Image Enhancement Featuring Reinforcement-Learning-Controlled Image Editing Software.**<br>
*Satoshi Kosugi, Toshihiko Yamasaki.* <br>
AAAI 2020. [[PDF](https://arxiv.org/abs/1912.07833)]

**Single Image Reflection Removal Exploiting Misaligned Training Data and Network Enhancements.**<br>
*Kaixuan Wei, Jiaolong Yang, Ying Fu, David Wipf, Hua Huang.* <br>
CVPR 2019. [[PDF](https://arxiv.org/abs/1904.00637)] [[Project](https://github.com/Vandermode/ERRNet)]

**Unpaired Image Enhancement Featuring Reinforcement-Learning-Controlled Image Editing Software.**<br>
*Kosugi, Toshihiko Yamasaki.*<br>
ArXiV, 17 Dec 2019 [[PDF](https://arxiv.org/pdf/1912.07833.pdfSatoshi)]

**Deep Photo Enhancer: Unpaired Learning for Image Enhancement from Photographs with GANs.**<br>
*Yu-Sheng Chen, Yu-Ching Wang, Man-Hsin Kao, Yung-Yu Chuang.*<br>
CVPR 2018. [[PDF](https://www.cmlab.csie.ntu.edu.tw/project/Deep-Photo-Enhancer/CVPR-2018-DPE.pdf)] [[Supplementary Material](https://www.cmlab.csie.ntu.edu.tw/project/Deep-Photo-Enhancer/CVPR-2018-DPE-sm-compress.pdf)] [[Demo](http://www.cmlab.csie.ntu.edu.tw/project/Deep-Photo-Enhancer/)] [[Github](https://github.com/nothinglo/Deep-Photo-Enhancer)]  [[MIT-Adobe FiveK Dataset](https://data.csail.mit.edu/graphics/fivek/)] [[DSLR Photo Enhancement Dataset](http://people.ee.ethz.ch/~ihnatova/#demo)]

**Probabilistic Noise2Void: Unsupervised Content-Aware Denoising.**<br>
*Alexander Krull, Tomas Vicar, Florian Jug.*<br>
[[PDF](https://arxiv.org/abs/1906.00651)] [[PN2V](https://github.com/juglab/pn2v)] [[PPN2V](https://github.com/juglab/ppn2v)]

## Vision, Language and Action

[Awesome Vision-and-Language Navigation](https://github.com/daqingliu/awesome-vln)

ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks.
Jiasen Lu, Dhruv Batra, Devi Parikh, Stefan Lee.
NeurIPS 2019. [[PDF](https://www.aminer.cn/pub/5db9297647c8f766461f745b/)] [[Github](https://github.com/jiasenlu/vilbert_beta)]

**ScanRefer: 3D Object Localization in RGB-D Scans using Natural Language.** <br>
*Dave Zhenyu Chen, Angel X. Chang, Matthias Nießner.*<br>
arxiv, 18 Dec 2019. [[PDF](https://arxiv.org/abs/1912.08830)]

**Reinforced Cross-Modal Matching and Self-Supervised Imitation Learning for Vision-Language Navigation.**<br>
*Xin Wang, Qiuyuan Huang, Asli Celikyilmaz, Jianfeng Gao, Dinghan Shen, Yuan-Fang Wang, William Yang Wang, Lei Zhang.*<br>
CVPR 2019 Oral. [[PDF](https://arxiv.org/abs/1811.10092)]

**Audio-Visual Embodied Navigation.**<br>
*Changan Chen, Unnat Jain, Carl Schissler, Sebastia Vicenc Amengual Gari, Ziad Al-Halah, Vamsi Krishna Ithapu, Philip Robinson, Kristen Grauman.*<br>
arxiv, 24 Dec 2019. [[PDF](https://arxiv.org/abs/1912.11474)] [[Project](http://vision.cs.utexas.edu/projects/audio_visual_navigation/)]

## Internal Learning

**SinGAN: Learning a Generative Model from a Single Natural Image.**<br>
*Tamar Rott Shaham, Tali Dekel, Tomer Michaeli.*<br>
ICCV 2019 (Best Paper). 
[[PDF](https://arxiv.org/abs/1905.01164)] [[UnOfficial](github.com/FriedRonaldo/SinGAN)] [[Official](github.com/tamarott/SinGAN)]

**InGAN: Capturing and Retargeting the DNA of a Natural Image.** <br>
ICCV 2019. [[PDF](http://www.wisdom.weizmann.ac.il/~vision/ingan/resources/ingan.pdf)] [[Homepage](http://www.wisdom.weizmann.ac.il/~vision/ingan/)] [[Github](https://github.com/assafshocher/InGAN)]

**An Internal Learning Approach to Video Inpainting.**<br>
*Haotian Zhang, Long Mai, Ning Xu, Zhaowen Wang, John Collomosse, Hailin Jin.*<br>
ICCV 2019.
[[PDF](https://arxiv.org/abs/1909.07957)]
[[Project](https://cs.stanford.edu/~haotianz/publications/video_inpainting/)]
[[Github](https://github.com/Haotianz94/IL_video_inpainting)]

**ZSSR: "Zero-Shot" Super-Resolution using Deep Internal Learning.**<br>
*Assaf Shocher, Nadav Cohen, Michal Irani.*<br>
CVPR 2018. [[PDF](https://arxiv.org/abs/1712.06087)][[GIthub](https://github.com/assafshocher/ZSSR)] [[Project](http://www.wisdom.weizmann.ac.il/~vision/zssr/)]

## Get-out-of-the-Lab: Real-World Applications

**ZIllumination Robust Monocular Direct Visual Odometry for Outdoor Environment Mapping.**<br>
*ZXiaolong Wu and Cedric Pradalier.*<br>
ICRA 2019.





