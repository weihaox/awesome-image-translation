## 2022

### NeurIPS 2022
[[accepted paper list](https://neurips.cc/virtual/2022/papers.html)]

**EGSDE: Unpaired Image-to-Image Translation via Energy-Guided Stochastic Differential Equations.** [[PDF](https://arxiv.org/abs/2207.06635)] [[Github](https://github.com/ML-GSAI/EGSDE)]<br>
*Min Zhao, Fan Bao, Chongxuan Li, Jun Zhu.*<br>

**Unsupervised Image-to-Image Translation with Density Changing Regularization.** [[PDF](https://openreview.net/pdf?id=RNZ8JOmNaV4)] [[Github](https://github.com/Mid-Push/Decent)]<br>
*Shaoan Xie, Qirong Ho, Kun Zhang.*<br>

### ECCV 2022
[[accepted paper list](https://www.ecva.net/papers.php)]

**RABIT: Bi-level Feature Alignment for Versatile Image Translation and Manipulation.** [[PDF](https://arxiv.org/abs/2107.03021)] [[Github](https://github.com/fnzhan/RABIT)]<br>
*Fangneng Zhan, Yingchen Yu, Rongliang Wu, Kaiwen Cui, Aoran Xiao, Shijian Lu, Ling Shao.*<br>

**Multi-Curve Translator for High-Resolution Photorealistic Image Translation.** [[PDF](https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136750124.pdf)]<br>
*Yuda Song, Hui Qian, Xin Du.*<br>

**Fast-Vid2Vid: Spatial-Temporal Compression for Video-to-Video Synthesis.** [[PDF](https://arxiv.org/abs/2207.05049)] [[Project](https://fast-vid2vid.github.io/)] [[Github](https://github.com/fast-vid2vid/fast-vid2vid)]<br> 
*Long Zhuo, Guangcong Wang, Shikai Li, Wayne Wu, Ziwei Liu.*<br> 

**ManiFest: Manifold Deformation for Few-shot Image Translation.** [[PDF](https://arxiv.org/abs/2111.13681)] [[GitHub](https://github.com/cv-rits/Manifest)]<br>
*[Fabio Pizzati](https://fabvio.github.io), [Jean-François Lalonde](http://vision.gel.ulaval.ca/~jflalonde/), [Raoul de Charette](https://team.inria.fr/rits/membres/raoul-de-charette/).*<br>

**Vector Quantized Image-to-Image Translation.** [[PDF](https://arxiv.org/abs/2207.13286)] [[Project](https://cyj407.github.io/VQ-I2I/)] [[Github](https://github.com/cyj407/VQ-I2I)]<br>
*[Yu-Jie Chen](cyj407.cs09g@nctu.edu.tw), [Shin-I Cheng](shinicheng.cs09g@nctu.edu.tw), [Wei-Chen Chiu](https://walonchiu.github.io/#publications), [Hung-Yu Tseng](https://hytseng0509.github.io/), [Hsin-Ying Lee](http://hsinyinglee.com/).*<br>

**Unpaired Image Translation via Vector Symbolic Architectures.** [[PDF](https://arxiv.org/abs/2209.02686)] [[Project](https://github.com/facebookresearch/vsait)]<br>
*Justin Theiss, Jay Leverett, Daeil Kim, Aayush Prakash.*

### CVPR 2022

**UNIST: Unpaired Neural Implicit Shape Translation Network.** [[PDF](https://arxiv.org/abs/2110.00966)] [[Project](https://qiminchen.github.io/unist/)] [[Github](https://github.com/qiminchen/UNIST)]<br>
*[Qimin Chen](https://qiminchen.github.io/), [Johannes Merz](), [Aditya Sanghi](https://www.autodesk.com/research/people/aditya-sanghi), [Hooman Shayani](https://www.autodesk.com/research/people/hooman-shayani), [Ali Mahdavi-Amiri](https://www.sfu.ca/~amahdavi/Home.html), [Hao (Richard) Zhang](https://www.cs.sfu.ca/~haoz/).*<br>

**DiffusionCLIP: Text-Guided Diffusion Models for Robust Image Manipulation.** [[PDF](https://arxiv.org/abs/2110.02711)] [[Github](https://github.com/gwang-kim/DiffusionCLIP)]<br>
*Gwanghyun Kim, Taesung Kwon, Jong Chul Ye.*<br>

**Exploring Patch-Wise Semantic Relation for Contrastive Learning in Image-to-Image Translation Tasks.** [[PDF](http://arxiv.org/abs/2203.01532)]<br> 
*Chanyong Jung, Gihyun Kwon, Jong Chul Ye.*<br> 

**InstaFormer: Instance-Aware Image-to-Image Translation with Transformer.** [[PDF](https://arxiv.org/abs/2203.16248)]<br> 
*Soohyun Kim, Jongbeom Baek, Jihye Park, Gyeongnyeon Kim, Seungryong Kim.*<br> 

**A Style-aware Discriminator for Controllable Image Translation.** [[PDF](https://arxiv.org/abs/2203.15375)] [[Github](https://github.com/kunheek/style-aware-discriminator)]<br> 
*[Kunhee Kim](https://www.kunheekim.xyz/), Sanghun Park, Eunyeong Jeon, Taehun Kim, Daijin Kim.*<br> 

**Maximum Spatial Perturbation Consistency for Unpaired Image-to-Image Translation.** [[PDF](https://arxiv.org/abs/2203.12707)][[Github](https://github.com/batmanlab/MSPC)]<br> 
*[Yanwu Xu](http://xuyanwu.github.io/), Shaoan Xie, Wenhao Wu, Kun Zhang, [Mingming Gong](https://mingming-gong.github.io/), [Kayhan Batmanghelich](https://kayhan.dbmi.pitt.edu/).*<br> 

**Modulated Contrast for Versatile Image Synthesis.** [[PDF](https://arxiv.org/abs/2203.09333)][[Github](https://github.com/fnzhan/MoNCE)]<br>
*[Fangneng Zhan](https://fnzhan.com), Jiahui Zhang, Yingchen Yu, Rongliang Wu, Shijian Lu.*<br> 

**Marginal Contrastive Correspondence for Guided Image Generation.** [[PDF](https://arxiv.org/abs/2204.00442)]<br>
*Fangneng Zhan, Yingchen Yu, Rongliang Wu, Jiahui Zhang, Shijian Lu, Changgong Zhang.*<br>

**QS-Attn: Query-Selected Attention for Contrastive Learning in I2I Translation.** [[PDF](https://arxiv.org/abs/2203.08483)][[Github](https://github.com/sapphire497/query-selected-attention)]<br>
*Xueqi Hu, Xinyue Zhou, Qiusheng Huang, Zhengyi Shi, Li Sun, Qingli Li.*<br> 

**Wavelet Knowledge Distillation: Towards Efficient Image-to-Image Translation.** [[PDF](https://arxiv.org/abs/2203.06321)]<br>
*Linfeng Zhang, Xin Chen, Xiaobing Tu, Pengfei Wan, Ning Xu, Kaisheng Ma.*<br> 

**Unsupervised Image-to-Image Translation with Generative Prior.** [[PDF](https://arxiv.org/abs/2204.03641)] [[Project](https://www.mmlab-ntu.com/project/gpunit/)] [[Github](https://github.com/williamyang1991/GP-UNIT)]<br> 
*[Shuai Yang](https://williamyang1991.github.io/), [Liming Jiang](https://liming-jiang.com/), Ziwei Liu, Chen Change Loy.*<br> 

**FlexIT: Towards Flexible Semantic Image Translation.** [[PDF](https://arxiv.org/abs/2203.04705)]<br> 
*Guillaume Couairon, Asya Grechka, Jakob Verbeek, Holger Schwenk, Matthieu Cord.*<br> 

### AAAI 2022

**OA-FSUI2IT: A Novel Few-Shot Cross Domain Object Detection Framework with Object-aware Few-shot Unsupervised Image-to-Image Translation.**<br> 
*Lifan Zhao, Yunlong Meng, Lin Xu.*<br> 

**Style-Guided and Disentangled Representation for Robust Image-to-Image Translation.**<br> 
*Jaewoong Choi, Daeha Kim, Byung Cheol Song.*<br> 

**Learning Temporally and Semantically Consistent Unpaired Video-to-Video Translation through PseudoSupervision from Synthetic Optical Flow.**<br> 
*Kaihong Wang, Kumar Akash, Teruhisa Misu.*<br> 

### Others 2022

**Image-to-Image Translation with Text Guidance.**<br>
*Bowen Li, Xiaojuan Qi, Philip H. S. Torr, Thomas Lukasiewicz.*<br>
BMVC 2022. [[PDF](https://arxiv.org/abs/2002.05235)]

**MixerGAN: An MLP-Based Architecture for Unpaired Image-to-Image Translation.**<br>
*George Cazenavette, Manuel Ladron De Guevara.*<br>
WACV 2022. [[PDF](https://arxiv.org/abs/2105.14110)]

**Beyond a Video Frame Interpolator: A Space Decoupled Learning Approach to Continuous Image Transition.**<br>
*[Tao Yang](https://cg.cs.tsinghua.edu.cn/people/~tyang), Peiran Ren, Xuansong Xie, Xiansheng Hua, Lei Zhang.*<br>
ECCV 2022 Workshop. [[PDF](https://arxiv.org/abs/2203.09771)] [[Github](https://github.com/yangxy/SDL)]

**Single Image Texture Translation for Data Augmentation.**<br>
*Boyi Li, Yin Cui, Tsung-Yi Lin, Serge Belongie.*<br>
ECCV 2022 Workshop on Learning from Limited and Imperfect Data (L2ID). [[PDF](https://arxiv.org/abs/2106.13804)] [[Github](https://github.com/Boyiliee/SITT)]

**StyleGAN-NADA: CLIP-Guided Domain Adaptation of Image Generators.**<br>
*[Rinon Gal](https://rinongal.github.io/), [Or Patashnik](https://orpatashnik.github.io/), [Haggai Maron](https://haggaim.github.io/), [Gal Chechik](https://research.nvidia.com/person/gal-chechik), [Daniel Cohen-Or](https://www.cs.tau.ac.il/~dcor/).*<br>
SIGGRAPH 2022. [[PDF](https://arxiv.org/abs/2108.00946)] [[Project](https://stylegan-nada.github.io/)] [[Github](https://github.com/rinongal/StyleGAN-nada)]

**Palette: Image-to-Image Diffusion Models.**<br>
*Chitwan Saharia, William Chan, Huiwen Chang, Chris A. Lee, Jonathan Ho, Tim Salimans, David J. Fleet, Mohammad Norouzi.*<br>
SIGGRAPH 2022. [[PDF](https://arxiv.org/abs/2111.05826)] [[Code](https://iterative-refinement.github.io/palette/)]

**Fix the Noise: Disentangling Source Feature for Transfer Learning of StyleGAN.**<br>
*Dongyeun Lee, Jae Young Lee, Doyeon Kim, Jaehyun Choi, Junmo Kim.*<br>
CVPR 2023/CVPR 2022 Workshop on AICC 2022 (Best Paper). [[PDF](https://arxiv.org/abs/2204.14079)] [[Code](https://github.com/LeeDongYeun/FixNoise)]

**Translating Images Into Maps.**<br>
*Avishkar Saha, Oscar Mendez Maldonado, Chris Russell, Richard Bowden.*<br>
ICRA 2022. [[PDF](https://arxiv.org/abs/2110.00966)] [[Github](https://github.com/avishkarsaha/translating-images-into-maps)]

**Leveraging Local Domains for Image-to-Image Translation.**<br>
*Anthony Dell'Eva, Fabio Pizzati, Massimo Bertozzi, Raoul de Charette.*<br>
VISAPP 2022 (Best Paper Award). [[PDF](https://arxiv.org/abs/2109.04468)]

**Unsupervised Multi-Modal Medical Image Registration via Discriminator-Free Image-to-Image Translation.**<br>
*Zekang Chen, Jia Wei, Rui Li.*<br>
IJCAI 2022. [[PDF](https://arxiv.org/abs/2204.13656)]

**Quality Metric Guided Portrait Line Drawing Generation from Unpaired Training Data.**<br>
*Ran Yi, Yong-Jin Liu, Yu-Kun Lai, Paul Rosin.*<br>
TPAMI 2022. [[PDF](https://ieeexplore.ieee.org/abstract/document/9699090)]

**ISF-GAN: An Implicit Style Function for High-Resolution Image-to-Image Translation.**<br>
*Yahui Liu, Yajing Chen, Linchao Bao, Nicu Sebe, Bruno Lepri, Marco De Nadai.*<br>
TMM 2022. [[PDF](https://arxiv.org/abs/2109.12492)] [[Github](https://github.com/yhlleo/stylegan-mmuit)]

**SAVI2I: Continuous and Diverse Image-to-Image Translation via Signed Attribute Vectors.**<br>
*Qi Mao, Hsin-Ying Lee, Hung-Yu Tseng, Jia-Bin Huang, Siwei Ma, Ming-Hsuan Yang.*<br>
IJCV 2022. [[PDF](https://arxiv.org/abs/2011.01215)] [[Project](https://helenmao.github.io/SAVI2I/)] [[Github](https://github.com/HelenMao/SAVI2I)]

**Distilling GANs with Style-Mixed Triplets for X2I Translation with Limited Data.**<br>
*Yaxing Wang, Joost van de weijer, Lu Yu, Shangling Jui.*<br>
ICLR 2022. [[PDF](https://openreview.net/forum?id=QjOQkpzKbNk)]

**Exploring Negatives in Contrastive Learning for Unpaired Image-to-Image Translation.**<br>
*Yupei Lin, Sen Zhang, Tianshui Chen, Yongyi Lu, Guangping Li, Yukai Shi.*<br>
ACM MM 2022. [[PDF](https://arxiv.org/abs/2204.11018)] [[Github](https://github.com/YupeiLin2388/Exploring-Negatives-in-Contrastive-Learning-for-Unpaired-Image-to-Image-Translation)]

**Pretraining is All You Need for Image-to-Image Translation.**<br>
*Tengfei Wang, Ting Zhang, Bo Zhang, Hao Ouyang, Dong Chen, Qifeng Chen, Fang Wen.*<br>
arxiv 2022. [[PDF](https://arxiv.org/abs/2205.12952)] [[Project](https://tengfei-wang.github.io/PITI/index.html)] [[Github](https://github.com/PITI-Synthesis/PITI)]

**The Swiss Army Knife for Image-to-Image Translation: Multi-Task Diffusion Models.**<br>
*Julia Wolleb, Robin Sandkühler, Florentin Bieder, Philippe C. Cattin.*<br>
arxiv 2022. [[PDF](https://arxiv.org/abs/2204.02641)]

**ITTR: Unpaired Image-to-Image Translation with Transformers.**<br>
*Wanfeng Zheng, Qiang Li, Guoxin Zhang, Pengfei Wan, Zhongyuan Wang.*<br>
arxiv 2022. [[PDF](https://arxiv.org/abs/2203.16015)] [[Github](https://github.com/lucidrains/ITTR-pytorch)]

